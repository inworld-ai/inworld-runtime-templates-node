"use strict";
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.RemoteLLMChatRoutingNode = void 0;
const snakify_1 = __importDefault(require("../utils/snakify"));
const abstract_node_1 = require("./abstract_node");
/**
 * Remote LLM chat routing node with intelligent fallback support.
 *
 * This node enables automatic routing and fallback to alternative LLM models
 * when the primary model fails, ensuring higher reliability for LLM-based
 * applications. Unlike RemoteLLMChatNode, this node handles model configuration
 * at runtime through the input LLMChatRoutingRequest.
 *
 * @input {LLMChatRoutingRequest} {@link GraphTypes.LLMChatRoutingRequest} - The
 * data type that LLMChatRoutingNode accepts as input
 * @output {LLMChatResponse} {@link GraphTypes.ContentStream } | {@link
 * GraphTypes.Content} - The data type that LLMChatRoutingNode outputs
 *
 * @example
 * ```typescript
 * // Create a routing node (API key is auto-injected)
 * const llmRoutingNode = new RemoteLLMChatRoutingNode({
 *   id: 'my-llm-routing-node',
 *   defaultTimeout: 30
 * });
 *
 * // The model configuration comes from the input request
 * const request = new GraphTypes.LLMChatRoutingRequest({
 *   messages: [...],
 *   modelId: { provider: 'groq', modelName: 'llama-3.1-70b-versatile' },
 *   routingConfig: {
 *     models: [
 *       { provider: 'openai', modelName: 'gpt-4o-mini' },
 *       { provider: 'openai', modelName: 'gpt-3.5-turbo' }
 *     ]
 *   },
 *   stream: true
 * });
 * ```
 */
class RemoteLLMChatRoutingNode extends abstract_node_1.AbstractNode {
    /**
     * Creates a new RemoteLLMChatRoutingNode instance.
     *
     * @param props - Configuration for the chat routing node.
     */
    constructor(props = {}) {
        var _a;
        super(props);
        this.defaultTimeout = props.defaultTimeout;
        this.executionConfig = {
            reportToClient: (_a = props.reportToClient) !== null && _a !== void 0 ? _a : false,
            defaults: props.defaults,
            strategy: props.strategy,
        };
    }
    toGraphConfigNode() {
        const creationConfig = {
            api_key: '{{INWORLD_API_KEY}}',
        };
        if (this.defaultTimeout !== undefined) {
            creationConfig.default_timeout = this.defaultTimeout;
        }
        return {
            id: this.id,
            type: 'LLMChatRoutingNode',
            creation_config: {
                type: 'LLMChatRoutingNodeCreationConfig',
                properties: creationConfig,
            },
            execution_config: {
                type: 'LLMChatRoutingNodeExecutionConfig',
                properties: (0, snakify_1.default)(this.executionConfig),
            },
        };
    }
}
exports.RemoteLLMChatRoutingNode = RemoteLLMChatRoutingNode;
