"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.intentSubgraph = void 0;
const DEFAULT_PROMPT_TEMPLATE = `
You are an intent classification model.
Your task is to select the most appropriate intent ID based on the provided query.

## Available Intents:
Each intent is defined by a unique intent ID and a set of representative training phrases. Use these examples to determine the best match.

Intent ID: 0
Intent Name: UNKNOWN
Use this when the query does not match any provided intent examples.

{% for intent in intents %}
Intent ID: {{intent['id']}}
Intent Name: {{ intent['name'] }}
{%- for phrase in intent['phrases'] %}
{{ phrase }}
{%- endfor -%}
{% if not loop.last %}{{ "\n" }}{% endif %}
{% endfor %}

Query:
{{ query }}

Guidelines:
1. Intent Matching: Compare the query against training phrases to determine the best fit.
2. Entity-Only Queries: If the query consists solely of an entity (e.g., a name, location, or object) with no action, return 0.
3. Ambiguity & Uncertainty: If the query is ambiguous, vague, or significantly different from provided examples, return 0.
4. Unclear or Too General Queries: If the query lacks sufficient context or is overly broad, return 0.
5. Confidence Threshold: If you are unsure, return 0.
6. Critical Accuracy: Correct classification is essential. Avoid incorrect matches.

Output Format:
1. Return exactly one intent ID from the list: [{% for intent_id in intent_ids %}{{ intent_id }}{% if not loop.last %}{{", "}}{% endif %}{% endfor %}].
2. Do not include any explanations or additional text-only the intent ID.

Return exactly one number from the list [{% for intent_id in intent_ids %}{{ intent_id }}{% if not loop.last %}{{", "}}{% endif %}{% endfor %}] without any additional text or explanation.

Intent ID:`;
const DEFAULT_INTENT_SUBGRAPH_CONFIG = {
    similarityThreshold: 0.88,
    textGenerationConfig: {},
    maxIntentsForLLM: 5,
    maxPhrasesPerIntent: 3,
    embeddingSimilarityThreshold: 0.7,
    topNIntents: 1,
};
const intentSubgraph = (parameters) => {
    var _a, _b, _c, _d, _e, _f, _g;
    const similarityThreshold = (_a = parameters.similarityThreshold) !== null && _a !== void 0 ? _a : DEFAULT_INTENT_SUBGRAPH_CONFIG.similarityThreshold;
    const textGenerationConfig = (_b = parameters.textGenerationConfig) !== null && _b !== void 0 ? _b : DEFAULT_INTENT_SUBGRAPH_CONFIG.textGenerationConfig;
    const maxIntentsForLLM = (_c = parameters.maxIntentsForLLM) !== null && _c !== void 0 ? _c : DEFAULT_INTENT_SUBGRAPH_CONFIG.maxIntentsForLLM;
    const maxPhrasesPerIntent = (_d = parameters.maxPhrasesPerIntent) !== null && _d !== void 0 ? _d : DEFAULT_INTENT_SUBGRAPH_CONFIG.maxPhrasesPerIntent;
    const embeddingSimilarityThreshold = (_e = parameters.embeddingSimilarityThreshold) !== null && _e !== void 0 ? _e : DEFAULT_INTENT_SUBGRAPH_CONFIG.embeddingSimilarityThreshold;
    const topNIntents = (_f = parameters.topNIntents) !== null && _f !== void 0 ? _f : DEFAULT_INTENT_SUBGRAPH_CONFIG.topNIntents;
    const promptTemplate = (_g = parameters.promptTemplate) !== null && _g !== void 0 ? _g : DEFAULT_PROMPT_TEMPLATE;
    return {
        id: 'intent_subgraph',
        nodes: [
            {
                id: 'input_node',
                type: 'ProxyNode',
            },
            {
                id: 'strict_match_node',
                type: 'Intent.StrictMatcherNode',
                creation_config: {
                    type: 'Intent.StrictMatcherNodeCreationConfig',
                    properties: {
                        intents: parameters.intents,
                    },
                },
            },
            {
                id: 'embedder_match_node',
                type: 'Intent.EmbeddingMatcherNode',
                creation_config: {
                    type: 'Intent.EmbeddingMatcherNodeCreationConfig',
                    properties: {
                        intents: parameters.intents,
                        embedder_component_id: parameters.embedderComponentId,
                    },
                },
                execution_config: {
                    type: 'Intent.EmbeddingMatcherNodeExecutionConfig',
                    properties: {
                        similarity_threshold: similarityThreshold,
                    },
                },
            },
            {
                id: 'llm_prompt_vars_node',
                type: 'Intent.LLMPromptVariablesBuilderNode',
                creation_config: {
                    type: 'Intent.LLMPromptVariablesBuilderNodeCreationConfig',
                    properties: {
                        intents: parameters.intents,
                    },
                },
                execution_config: {
                    type: 'Intent.LLMPromptVariablesBuilderNodeExecutionConfig',
                    properties: {
                        //max_intents_for_llm: maxIntentsForLLM,
                        max_intents: maxIntentsForLLM,
                        max_phrases_per_intent: maxPhrasesPerIntent,
                        // embedding_similarity_threshold: similarityThreshold,
                    },
                },
            },
            {
                id: 'llm_chat_node',
                type: 'LLMChatNode',
                execution_config: {
                    type: 'LLMChatNodeExecutionConfig',
                    properties: {
                        llm_component_id: parameters.llmComponentId,
                        text_generation_config: textGenerationConfig,
                        message_templates: [
                            {
                                role: 'user',
                                // TextContentItem with Jinja template in the text field
                                content: [{ type: 'text', text: promptTemplate }],
                            },
                        ],
                    },
                },
            },
            {
                id: 'llm_response_parser_node',
                type: 'Intent.LLMResponseParserNode',
            },
            {
                id: 'top_n_filter_node',
                type: 'Intent.OutputNode',
                execution_config: {
                    type: 'Intent.OutputNodeExecutionConfig',
                    properties: {
                        top_n_intents: topNIntents,
                    },
                },
            },
        ],
        edges: [
            { from_node: 'input_node', to_node: 'strict_match_node' },
            { from_node: 'input_node', to_node: 'embedder_match_node' },
            { from_node: 'input_node', to_node: 'llm_prompt_vars_node' },
            {
                from_node: 'strict_match_node',
                to_node: 'top_n_filter_node',
                condition_expression: `size(input.intent_matches) >= ${topNIntents}`,
                optional: true,
            },
            {
                from_node: 'strict_match_node',
                to_node: 'embedder_match_node',
                condition_expression: `size(input.intent_matches) <  ${topNIntents}`,
            },
            {
                from_node: 'embedder_match_node',
                to_node: 'top_n_filter_node',
                condition_expression: `size(input.intent_matches.filter(x, x.score >= ${embeddingSimilarityThreshold})) >= ${topNIntents}`,
                optional: true,
            },
            {
                from_node: 'embedder_match_node',
                to_node: 'llm_prompt_vars_node',
                condition_expression: `size(input.intent_matches.filter(x, x.score >= ${embeddingSimilarityThreshold})) < ${topNIntents}`,
            },
            {
                from_node: 'llm_prompt_vars_node',
                to_node: 'llm_chat_node',
            },
            { from_node: 'llm_chat_node', to_node: 'llm_response_parser_node' },
            {
                from_node: 'llm_prompt_vars_node',
                to_node: 'llm_response_parser_node',
            },
            {
                from_node: 'llm_response_parser_node',
                to_node: 'top_n_filter_node',
                optional: true,
            },
        ],
        start_nodes: ['input_node'],
        end_nodes: ['top_n_filter_node'],
    };
};
exports.intentSubgraph = intentSubgraph;
