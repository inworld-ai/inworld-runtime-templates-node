"use strict";
/**
 * AEC Filter primitive using N-API addon.
 * AEC (Acoustic Echo Cancellation) removes speaker output from microphone input.
 */
var __await = (this && this.__await) || function (v) { return this instanceof __await ? (this.v = v, this) : new __await(v); }
var __asyncValues = (this && this.__asyncValues) || function (o) {
    if (!Symbol.asyncIterator) throw new TypeError("Symbol.asyncIterator is not defined.");
    var m = o[Symbol.asyncIterator], i;
    return m ? m.call(o) : (o = typeof __values === "function" ? __values(o) : o[Symbol.iterator](), i = {}, verb("next"), verb("throw"), verb("return"), i[Symbol.asyncIterator] = function () { return this; }, i);
    function verb(n) { i[n] = o[n] && function (v) { return new Promise(function (resolve, reject) { v = o[n](v), settle(resolve, reject, v.done, v.value); }); }; }
    function settle(resolve, reject, d, v) { Promise.resolve(v).then(function(v) { resolve({ value: v, done: d }); }, reject); }
};
var __asyncGenerator = (this && this.__asyncGenerator) || function (thisArg, _arguments, generator) {
    if (!Symbol.asyncIterator) throw new TypeError("Symbol.asyncIterator is not defined.");
    var g = generator.apply(thisArg, _arguments || []), i, q = [];
    return i = Object.create((typeof AsyncIterator === "function" ? AsyncIterator : Object).prototype), verb("next"), verb("throw"), verb("return", awaitReturn), i[Symbol.asyncIterator] = function () { return this; }, i;
    function awaitReturn(f) { return function (v) { return Promise.resolve(v).then(f, reject); }; }
    function verb(n, f) { if (g[n]) { i[n] = function (v) { return new Promise(function (a, b) { q.push([n, v, a, b]) > 1 || resume(n, v); }); }; if (f) i[n] = f(i[n]); } }
    function resume(n, v) { try { step(g[n](v)); } catch (e) { settle(q[0][3], e); } }
    function step(r) { r.value instanceof __await ? Promise.resolve(r.value.v).then(fulfill, reject) : settle(q[0][2], r); }
    function fulfill(value) { resume("next", value); }
    function reject(value) { resume("throw", value); }
    function settle(f, v) { if (f(v), q.shift(), q.length) resume(q[0][0], q[0][1]); }
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.AECFilter = void 0;
const node_api_1 = require("../../internal/node_api");
const pb_helpers_1 = require("../../internal/pb_helpers");
const errors_1 = require("../errors");
/**
 * AEC Filter class.
 * Filters out acoustic echo from microphone audio by removing speaker output.
 * Essential for full-duplex voice communication to prevent feedback loops.
 *
 * @example
 * ```typescript
 * // Create AEC filter
 * const aecFilter = await AECFilter.create({
 *   localConfig: {
 *     filterLengthMs: 200,  // Echo tail length in milliseconds
 *     device: { type: 'CPU', index: 0 }
 *   }
 * });
 *
 * // Filter audio to remove echo
 * const filteredAudio = await aecFilter.filterAudio(
 *   microphoneChunk,  // Audio from microphone
 *   speakersChunk     // Audio playing through speakers
 * );
 *
 * // Use filtered audio for speech recognition
 * const text = await stt.recognizeSpeech(filteredAudio);
 * ```
 */
class AECFilter {
    /**
     * Creates a new AECFilter instance (internal constructor).
     * Use `AECFilter.create()` static method instead.
     *
     * @param {any} aecFilterInterface - Addon AECFilterInterface instance
     * @internal
     */
    constructor(aecFilterInterface) {
        this.aecFilterInterface = aecFilterInterface;
    }
    /**
     * Creates a new AECFilter instance with the specified configuration.
     * Currently only supports local (on-device) processing.
     *
     * @param {AECFilterCreationConfig} config - AEC filter configuration
     * @returns {Promise<AECFilter>} Promise resolving to AECFilter instance
     * @throws {AECFilterError} If AEC filter creation fails
     *
     * @example
     * ```typescript
     * const aecFilter = await AECFilter.create({
     *   localConfig: {
     *     filterLengthMs: 200,  // Echo tail length
     *     device: {
     *       type: 'CPU',
     *       index: 0
     *     }
     *   }
     * });
     * ```
     */
    static async create(config) {
        try {
            const env = (0, node_api_1.getInworldAddonEnv)();
            const speech = env.speech;
            if (!speech) {
                throw new errors_1.AECFilterError('Speech namespace not available in addon environment');
            }
            const factory = speech.createAECFilterFactory();
            const configPb = pb_helpers_1.PbHelper.Speech.createAECFilterCreationConfig(config);
            const aecFilterInterface = await factory.createAECFilter(configPb);
            return new AECFilter(aecFilterInterface);
        }
        catch (error) {
            if (error instanceof errors_1.AECFilterError) {
                throw error;
            }
            throw new errors_1.AECFilterError(`Failed to create AEC filter: ${error.message}`, error.stack);
        }
    }
    /**
     * Filters audio to remove acoustic echo.
     * Takes microphone input and speaker output, returns filtered microphone audio.
     *
     * @param {AudioChunk} microphoneChunk - Audio from microphone
     * @param {AudioChunk} speakersChunk - Audio playing through speakers
     * @param {AECFilterConfig} config - Optional filter config
     * @returns {Promise<AudioFrame>} Filtered audio frame
     * @throws {AECFilterError} If filtering fails
     *
     * @example
     * ```typescript
     * // Capture audio from both sources
     * const micAudio = {
     *   data: new Float32Array(micBuffer),
     *   sampleRate: 16000
     * };
     *
     * const speakerAudio = {
     *   data: new Float32Array(speakerBuffer),
     *   sampleRate: 16000
     * };
     *
     * // Filter to remove echo
     * const filtered = await aecFilter.filterAudio(micAudio, speakerAudio);
     *
     * // Use filtered audio for processing
     * console.log('Filtered samples:', filtered.data.length);
     * ```
     */
    async filterAudio(microphoneChunk, speakersChunk, config) {
        try {
            if (!microphoneChunk || !microphoneChunk.data) {
                throw new errors_1.AECFilterError('Microphone audio data is required');
            }
            if (!speakersChunk || !speakersChunk.data) {
                throw new errors_1.AECFilterError('Speakers audio data is required');
            }
            if (microphoneChunk.sampleRate !== speakersChunk.sampleRate) {
                throw new errors_1.AECFilterError('Microphone and speakers audio must have the same sample rate');
            }
            const requestPb = pb_helpers_1.PbHelper.Speech.createFilterAudioRequest({
                microphoneChunk,
                speakersChunk,
                config,
            });
            const resultPb = await this.aecFilterInterface.filterAudio(requestPb);
            return pb_helpers_1.PbHelper.Speech.unpackAudioFrame(resultPb);
        }
        catch (error) {
            if (error instanceof errors_1.AECFilterError) {
                throw error;
            }
            throw new errors_1.AECFilterError(`Failed to filter audio: ${error.message}`, error.stack);
        }
    }
    /**
     * Streams filtered audio frames.
     * Processes audio chunks continuously and yields filtered frames.
     *
     * @param {AudioChunk} microphoneChunk - Initial microphone audio
     * @param {AudioChunk} speakersChunk - Initial speakers audio
     * @param {AECFilterConfig} config - Optional filter config
     * @returns {AsyncIterable<AudioFrame>} Stream of filtered audio frames
     * @throws {AECFilterError} If streaming fails
     *
     * @example
     * ```typescript
     * // Stream filtered audio
     * const stream = aecFilter.streamFilterAudio(micAudio, speakerAudio);
     *
     * for await (const filteredFrame of stream) {
     *   console.log('Filtered frame:', filteredFrame.data.length, 'samples');
     *   // Process each filtered frame
     *   await processAudio(filteredFrame);
     * }
     * ```
     */
    streamFilterAudio(microphoneChunk, speakersChunk, config) {
        return __asyncGenerator(this, arguments, function* streamFilterAudio_1() {
            var _a, e_1, _b, _c;
            try {
                if (!microphoneChunk || !microphoneChunk.data) {
                    throw new errors_1.AECFilterError('Microphone audio data is required');
                }
                if (!speakersChunk || !speakersChunk.data) {
                    throw new errors_1.AECFilterError('Speakers audio data is required');
                }
                const requestPb = pb_helpers_1.PbHelper.Speech.createFilterAudioRequest({
                    microphoneChunk,
                    speakersChunk,
                    config,
                });
                const streamIterator = yield __await(this.aecFilterInterface.streamFilterAudio(requestPb));
                try {
                    for (var _d = true, streamIterator_1 = __asyncValues(streamIterator), streamIterator_1_1; streamIterator_1_1 = yield __await(streamIterator_1.next()), _a = streamIterator_1_1.done, !_a; _d = true) {
                        _c = streamIterator_1_1.value;
                        _d = false;
                        const framePb = _c;
                        yield yield __await(pb_helpers_1.PbHelper.Speech.unpackAudioFrame(framePb));
                    }
                }
                catch (e_1_1) { e_1 = { error: e_1_1 }; }
                finally {
                    try {
                        if (!_d && !_a && (_b = streamIterator_1.return)) yield __await(_b.call(streamIterator_1));
                    }
                    finally { if (e_1) throw e_1.error; }
                }
            }
            catch (error) {
                if (error instanceof errors_1.AECFilterError) {
                    throw error;
                }
                throw new errors_1.AECFilterError(`Failed to stream filtered audio: ${error.message}`, error.stack);
            }
        });
    }
    /**
     * Filters multiple audio chunk pairs in batch.
     *
     * @param {Array<{mic: AudioChunk, speakers: AudioChunk}>} chunkPairs - Pairs of audio chunks
     * @param {AECFilterConfig} config - Optional filter config
     * @returns {Promise<AudioFrame[]>} Array of filtered audio frames
     * @throws {AECFilterError} If filtering fails
     *
     * @example
     * ```typescript
     * const pairs = [
     *   { mic: micChunk1, speakers: speakerChunk1 },
     *   { mic: micChunk2, speakers: speakerChunk2 },
     *   { mic: micChunk3, speakers: speakerChunk3 }
     * ];
     *
     * const filtered = await aecFilter.filterBatch(pairs);
     *
     * filtered.forEach((frame, i) => {
     *   console.log(`Frame ${i + 1}: ${frame.data.length} samples`);
     * });
     * ```
     */
    async filterBatch(chunkPairs, config) {
        if (!Array.isArray(chunkPairs)) {
            throw new errors_1.AECFilterError('Chunk pairs must be an array');
        }
        return Promise.all(chunkPairs.map((pair) => this.filterAudio(pair.mic, pair.speakers, config)));
    }
    /**
     * Filters continuous audio streams from microphone and speakers.
     *
     * @param {AsyncIterable<AudioChunk>} micStream - Microphone audio stream
     * @param {AsyncIterable<AudioChunk>} speakerStream - Speakers audio stream
     * @param {AECFilterConfig} config - Optional filter config
     * @returns {AsyncGenerator<AudioFrame>} Stream of filtered frames
     * @throws {AECFilterError} If filtering fails
     *
     * @example
     * ```typescript
     * async function filterFullDuplex(micStream, speakerStream) {
     *   for await (const filtered of aecFilter.filterStreams(micStream, speakerStream)) {
     *     // Send filtered audio to speech recognition
     *     await stt.recognizeSpeech(filtered);
     *   }
     * }
     * ```
     */
    filterStreams(micStream, speakerStream, config) {
        return __asyncGenerator(this, arguments, function* filterStreams_1() {
            try {
                const micIterator = micStream[Symbol.asyncIterator]();
                const speakerIterator = speakerStream[Symbol.asyncIterator]();
                while (true) {
                    const [micResult, speakerResult] = yield __await(Promise.all([
                        micIterator.next(),
                        speakerIterator.next(),
                    ]));
                    if (micResult.done || speakerResult.done) {
                        break;
                    }
                    const filtered = yield __await(this.filterAudio(micResult.value, speakerResult.value, config));
                    yield yield __await(filtered);
                }
            }
            catch (error) {
                if (error instanceof errors_1.AECFilterError) {
                    throw error;
                }
                throw new errors_1.AECFilterError(`Failed to filter streams: ${error.message}`, error.stack);
            }
        });
    }
    /**
     * Checks if audio contains significant echo that needs filtering.
     * Compares microphone and speaker signals to estimate echo level.
     *
     * @param {AudioChunk} microphoneChunk - Microphone audio
     * @param {AudioChunk} speakersChunk - Speakers audio
     * @returns {Promise<boolean>} True if echo is detected
     * @throws {AECFilterError} If detection fails
     *
     * @example
     * ```typescript
     * const hasEcho = await aecFilter.detectEcho(micAudio, speakerAudio);
     *
     * if (hasEcho) {
     *   console.log('Echo detected, applying filter');
     *   const filtered = await aecFilter.filterAudio(micAudio, speakerAudio);
     * } else {
     *   console.log('No significant echo, using original audio');
     * }
     * ```
     */
    async detectEcho(microphoneChunk, speakersChunk) {
        try {
            // Simple echo detection: compare energy levels
            const micEnergy = this.calculateEnergy(microphoneChunk.data);
            const speakerEnergy = this.calculateEnergy(speakersChunk.data);
            // If speaker energy is significant and microphone has similar energy,
            // likely echo is present
            return speakerEnergy > 0.01 && micEnergy / speakerEnergy > 0.3;
        }
        catch (error) {
            throw new errors_1.AECFilterError(`Failed to detect echo: ${error.message}`, error.stack);
        }
    }
    /**
     * Calculates audio signal energy (RMS).
     * @private
     */
    calculateEnergy(data) {
        let sum = 0;
        for (let i = 0; i < data.length; i++) {
            sum += data[i] * data[i];
        }
        return Math.sqrt(sum / data.length);
    }
}
exports.AECFilter = AECFilter;
