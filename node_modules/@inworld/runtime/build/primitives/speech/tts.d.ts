/**
 * Text-to-Speech (TTS) primitive using N-API addon.
 */
import type { AudioChunk, SynthesizeSpeechRequest, TTSCreationConfig } from './types';
/**
 * Text-to-Speech (TTS) class.
 * Synthesizes natural-sounding speech from text.
 * Supports both local models and cloud-based APIs.
 *
 * @example
 * ```typescript
 * // Create TTS instance with cloud API
 * const tts = await TTS.create({
 *   remoteConfig: {
 *     apiKey: process.env.INWORLD_API_KEY,
 *     defaultConfig: {
 *       voice: 'en-US-Neural2-A',
 *       sampleRateHz: 24000
 *     },
 *     defaultTimeout: { seconds: 30 }
 *   }
 * });
 *
 * // Synthesize speech
 * const stream = await tts.synthesizeSpeech({
 *   voice: 'en-US-Neural2-A',
 *   text: 'Hello, world!'
 * });
 *
 * for await (const audioChunk of stream) {
 *   // Play or save audio chunk
 *   console.log('Received audio:', audioChunk.data.length, 'samples');
 * }
 * ```
 */
export declare class TTS {
    private ttsInterface;
    /**
     * Creates a new TTS instance (internal constructor).
     * Use `TTS.create()` static method instead.
     *
     * @param {any} ttsInterface - Addon TTSInterface instance
     * @internal
     */
    constructor(ttsInterface: any);
    /**
     * Creates a new TTS instance with the specified configuration.
     *
     * @param {TTSCreationConfig} config - TTS creation configuration
     * @returns {Promise<TTS>} Promise resolving to TTS instance
     * @throws {TTSError} If TTS creation fails
     *
     * @example
     * ```typescript
     * // Local model
     * const tts = await TTS.create({
     *   localConfig: {
     *     modelPath: 'models/tts/torch-tts',
     *     device: { type: 'CPU', index: 0 },
     *     defaultConfig: {
     *       voice: 'default',
     *       sampleRateHz: 22050
     *     }
     *   }
     * });
     *
     * // Cloud API
     * const tts = await TTS.create({
     *   remoteConfig: {
     *     apiKey: process.env.INWORLD_API_KEY,
     *     defaultConfig: {
     *       voice: 'en-US-Neural2-A',
     *       sampleRateHz: 24000
     *     },
     *     defaultTimeout: { seconds: 30 }
     *   }
     * });
     * ```
     */
    static create(config: TTSCreationConfig): Promise<TTS>;
    /**
     * Synthesizes speech from text and returns a stream of audio chunks.
     * The stream yields audio data as it becomes available.
     *
     * @param {SynthesizeSpeechRequest} request - Synthesis request with voice and text
     * @returns {Promise<AsyncIterable<AudioChunk>>} Stream of audio chunks
     * @throws {TTSError} If speech synthesis fails
     *
     * @example
     * ```typescript
     * const stream = await tts.synthesizeSpeech({
     *   voice: 'en-US-Neural2-A',
     *   text: 'Hello, world! How are you today?'
     * });
     *
     * const audioChunks: Float32Array[] = [];
     * for await (const chunk of stream) {
     *   audioChunks.push(chunk.data);
     *   console.log('Received chunk:', chunk.data.length, 'samples at', chunk.sampleRate, 'Hz');
     * }
     *
     * // Concatenate all chunks
     * const totalLength = audioChunks.reduce((sum, arr) => sum + arr.length, 0);
     * const fullAudio = new Float32Array(totalLength);
     * let offset = 0;
     * for (const chunk of audioChunks) {
     *   fullAudio.set(chunk, offset);
     *   offset += chunk.length;
     * }
     * ```
     */
    synthesizeSpeech(request: SynthesizeSpeechRequest): Promise<AsyncIterable<AudioChunk>>;
    /**
     * Transforms protobuf stream to audio chunk stream.
     * @param {AsyncIterable<any>} pbStream - Protobuf message stream
     * @returns {AsyncIterable<AudioChunk>} Audio chunk stream
     * @private
     */
    private transformPbStreamToAudio;
    /**
     * Convenience method to synthesize speech and return complete audio.
     * Waits for the entire stream to complete and concatenates all chunks.
     *
     * @param {SynthesizeSpeechRequest} request - Synthesis request
     * @returns {Promise<AudioChunk>} Complete audio as single chunk
     * @throws {TTSError} If speech synthesis fails
     *
     * @example
     * ```typescript
     * const audio = await tts.synthesizeSpeechComplete({
     *   voice: 'en-US-Neural2-A',
     *   text: 'Hello, world!'
     * });
     *
     * console.log('Generated audio:', audio.data.length, 'samples');
     * console.log('Sample rate:', audio.sampleRate, 'Hz');
     *
     * // Save to file or play
     * ```
     */
    synthesizeSpeechComplete(request: SynthesizeSpeechRequest): Promise<AudioChunk>;
    /**
     * Synthesizes speech from text with simpler API (uses defaults from config).
     *
     * @param {string} text - Text to synthesize
     * @param {string} voice - Optional voice override
     * @returns {Promise<AsyncIterable<AudioChunk>>} Stream of audio chunks
     * @throws {TTSError} If speech synthesis fails
     *
     * @example
     * ```typescript
     * const stream = await tts.speak('Hello, world!');
     *
     * for await (const chunk of stream) {
     *   // Process audio chunk
     * }
     * ```
     */
    speak(text: string, voice?: string): Promise<AsyncIterable<AudioChunk>>;
}
