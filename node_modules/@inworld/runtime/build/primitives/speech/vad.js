"use strict";
/**
 * Voice Activity Detection (VAD) primitive using N-API addon.
 */
Object.defineProperty(exports, "__esModule", { value: true });
exports.VAD = void 0;
const node_api_1 = require("../../internal/node_api");
const pb_helpers_1 = require("../../internal/pb_helpers");
const errors_1 = require("../errors");
/**
 * Voice Activity Detection (VAD) class.
 * Detects voice activity and silence in audio streams.
 *
 * @example
 * ```typescript
 * // Create VAD instance
 * const vad = await VAD.create({
 *   localConfig: {
 *     modelPath: 'models/vad/silero/silero_vad.onnx',
 *     device: { type: 'CPU', index: 0 },
 *     defaultConfig: { speechThreshold: 0.5 }
 *   }
 * });
 *
 * // Detect voice activity
 * const speechStartSample = await vad.detectVoiceActivity(audioChunk);
 * if (speechStartSample !== -1) {
 *   console.log(`Speech detected at sample ${speechStartSample}`);
 * }
 *
 * // Detect silence intervals
 * const silenceIntervals = await vad.detectSilence(audioBytes, sampleRate);
 * ```
 */
class VAD {
    /**
     * Creates a new VAD instance (internal constructor).
     * Use `VAD.create()` static method instead.
     *
     * @param {any} vadInterface - Addon VADInterface instance
     * @internal
     */
    constructor(vadInterface) {
        this.vadInterface = vadInterface;
    }
    /**
     * Creates a new VAD instance with the specified configuration.
     *
     * @param {VADCreationConfig} config - VAD creation configuration
     * @returns {Promise<VAD>} Promise resolving to VAD instance
     * @throws {VADError} If VAD creation fails
     *
     * @example
     * ```typescript
     * const vad = await VAD.create({
     *   localConfig: {
     *     modelPath: 'models/vad/silero/silero_vad.onnx',
     *     device: { type: 'CPU', index: 0 },
     *     defaultConfig: { speechThreshold: 0.5 }
     *   }
     * });
     * ```
     */
    static async create(config) {
        try {
            const env = (0, node_api_1.getInworldAddonEnv)();
            const speech = env.speech;
            if (!speech) {
                throw new errors_1.VADError('Speech namespace not available in addon environment');
            }
            const factory = speech.createVADFactory();
            const configPb = pb_helpers_1.PbHelper.Speech.createVADCreationConfig(config);
            const vadInterface = await factory.createVAD(configPb);
            return new VAD(vadInterface);
        }
        catch (error) {
            if (error instanceof errors_1.VADError) {
                throw error;
            }
            throw new errors_1.VADError(`Failed to create VAD instance: ${error.message}`, error.stack);
        }
    }
    /**
     * Detects voice activity in the provided audio chunk.
     * Returns the sample index where speech begins, or -1 if no speech is detected.
     *
     * @param {AudioChunk} audio - Audio chunk to analyze
     * @param {VADConfig} config - Optional VAD configuration
     * @returns {Promise<number>} Sample index where speech starts, or -1 if no speech
     * @throws {VADError} If voice activity detection fails
     *
     * @example
     * ```typescript
     * const speechStartSample = await vad.detectVoiceActivity(
     *   { data: audioData, sampleRate: 16000 },
     *   { speechThreshold: 0.5 }
     * );
     *
     * if (speechStartSample !== -1) {
     *   console.log(`Speech detected at sample ${speechStartSample}`);
     * } else {
     *   console.log('No speech detected');
     * }
     * ```
     */
    async detectVoiceActivity(audio, config) {
        try {
            const requestPb = pb_helpers_1.PbHelper.Speech.createDetectVoiceActivityRequest(audio, config);
            return await this.vadInterface.detectVoiceActivity(requestPb);
        }
        catch (error) {
            throw new errors_1.VADError(`Failed to detect voice activity: ${error.message}`, error.stack);
        }
    }
    /**
     * Detects silence intervals in the provided audio data.
     * Returns an array of silence intervals with start and end sample indices.
     *
     * @param {Buffer} audioBytes - Raw audio bytes
     * @param {number} sampleRate - Audio sample rate in Hz
     * @param {VADConfig} config - Optional VAD configuration
     * @returns {Promise<SilenceInterval[]>} Array of silence intervals
     * @throws {VADError} If silence detection fails
     *
     * @example
     * ```typescript
     * const silenceIntervals = await vad.detectSilence(
     *   audioBuffer,
     *   16000,
     *   { speechThreshold: 0.5 }
     * );
     *
     * silenceIntervals.forEach(interval => {
     *   console.log(`Silence from ${interval.start} to ${interval.end}`);
     * });
     * ```
     */
    async detectSilence(audioBytes, sampleRate, config) {
        try {
            const requestPb = pb_helpers_1.PbHelper.Speech.createDetectSilenceRequest(audioBytes, sampleRate, config);
            return await this.vadInterface.detectSilence(requestPb);
        }
        catch (error) {
            throw new errors_1.VADError(`Failed to detect silence: ${error.message}`, error.stack);
        }
    }
    /**
     * Streaming voice activity detection (not yet implemented in addon).
     *
     * @param {AudioChunk} audio - Audio chunk
     * @param {VADConfig} config - Optional VAD configuration
     * @returns {Promise<AsyncIterable<number>>} Stream of voice activity scores
     * @throws {VADError} Always throws - not implemented
     *
     * @deprecated Not yet implemented in addon
     */
    async streamDetectVoiceActivity(_audio, _config) {
        throw new errors_1.VADError('streamDetectVoiceActivity is not yet implemented in the addon');
    }
}
exports.VAD = VAD;
