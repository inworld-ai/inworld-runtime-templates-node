/**
 * Streaming Speech-to-Text (StreamingSTT) primitive using N-API addon.
 * Handles real-time speech recognition from continuous audio streams.
 */
import type { AudioChunk, StreamingSTTCreationConfig, StreamingSTTSession, StreamRecognizeSpeechRequestOptions } from './types';
/**
 * Streaming Speech-to-Text (StreamingSTT) class.
 * Converts continuous audio streams into real-time text transcriptions.
 * Supports both local models and cloud-based APIs with automatic chunking.
 *
 * @example
 * ```typescript
 * // Create StreamingSTT instance with cloud API
 * const streamingSTT = await StreamingSTT.create({
 *   remoteConfig: {
 *     apiKey: process.env.INWORLD_API_KEY,
 *     defaultConfig: {
 *       languageCode: 'en-US',
 *       silenceThresholdMs: 1500
 *     },
 *     defaultTimeout: { seconds: 30 }
 *   }
 * });
 *
 * // Create audio stream generator
 * async function* audioStreamGenerator() {
 *   for (const audioChunk of audioChunks) {
 *     yield audioChunk;
 *   }
 * }
 *
 * // Recognize speech from stream
 * const textStream = await streamingSTT.recognizeSpeechStream(
 *   audioStreamGenerator()
 * );
 *
 * for await (const transcription of textStream) {
 *   console.log('Transcription:', transcription);
 * }
 * ```
 */
export declare class StreamingSTT {
    private streamingSTTInterface;
    /**
     * Creates a new StreamingSTT instance (internal constructor).
     * Use `StreamingSTT.create()` static method instead.
     *
     * @param {any} streamingSTTInterface - Addon StreamingSTTInterface instance
     * @internal
     */
    constructor(streamingSTTInterface: any);
    /**
     * Creates a new StreamingSTT instance with the specified configuration.
     *
     * @param {StreamingSTTCreationConfig} config - StreamingSTT creation configuration
     * @returns {Promise<StreamingSTT>} Promise resolving to StreamingSTT instance
     * @throws {STTError} If StreamingSTT creation fails
     *
     * @example
     * ```typescript
     * // Local model
     * const streamingSTT = await StreamingSTT.create({
     *   localConfig: {
     *     sttModelPath: 'models/stt/whisper-base',
     *     vadModelPath: 'models/vad/silero_vad.onnx',
     *     sttDevice: { type: 'CPU', index: 0 },
     *     vadDevice: { type: 'CPU', index: 0 },
     *     defaultConfig: {
     *       languageCode: 'en-US',
     *       silenceThresholdMs: 1500
     *     }
     *   }
     * });
     *
     * // Cloud API
     * const streamingSTT = await StreamingSTT.create({
     *   remoteConfig: {
     *     apiKey: process.env.INWORLD_API_KEY,
     *     defaultConfig: {
     *       languageCode: 'en-US',
     *       silenceThresholdMs: 1500
     *     },
     *     defaultTimeout: { seconds: 30 }
     *   }
     * });
     * ```
     */
    static create(config: StreamingSTTCreationConfig): Promise<StreamingSTT>;
    /**
     * Recognizes speech from a continuous audio stream.
     * The audio stream should yield audio chunks as they become available.
     * Returns a stream of transcriptions that update as speech is detected.
     *
     * @param {AsyncIterable<AudioFrame>} audioStream - Stream of audio chunks
     * @param {StreamRecognizeSpeechRequestOptions} [options] - Optional recognition overrides
     * @returns {Promise<AsyncIterable<string>>} Stream of text transcriptions
     * @throws {STTError} If speech recognition fails
     *
     * @example
     * ```typescript
     * // Create audio stream generator
     * async function* audioStreamGenerator() {
     *   for (const chunk of audioChunks) {
     *     yield {
     *       data: chunk.data,      // Float32Array
     *       sampleRate: 16000
     *     };
     *   }
     * }
     *
     * const textStream = await streamingSTT.recognizeSpeechStream(
     *   audioStreamGenerator()
     * );
     *
     * for await (const transcription of textStream) {
     *   console.log('Transcription:', transcription);
     * }
     * ```
     */
    recognizeSpeechStream(audioStream: AsyncIterable<AudioChunk>, options?: StreamRecognizeSpeechRequestOptions): Promise<AsyncIterable<string>>;
    /**
     * Starts a streaming recognition session and exposes the underlying
     * transcription iterator together with a cancellation hook.
     *
     * @param {AsyncIterable<AudioFrame>} audioStream - Audio chunk stream
     * @param {StreamRecognizeSpeechRequestOptions} [options] - Optional overrides
     * @returns {Promise<StreamingSTTSession>} Streaming session
     */
    startRecognizeSpeechSession(audioStream: AsyncIterable<AudioChunk>, options?: StreamRecognizeSpeechRequestOptions): Promise<StreamingSTTSession>;
    /**
     * Transforms audio stream to protobuf audio stream.
     * @param {AsyncIterable<AudioFrame>} audioStream - Audio chunk stream
     * @returns {AsyncIterable<any>} Protobuf audio chunk stream
     * @private
     */
    private transformAudioStreamToPb;
    /**
     * Pipes protobuf audio frames into the bidirectional stream.
     * @param {AsyncIterable<any>} pbAudioStream - Audio frames encoded as protobuf
     * @param {any} bidirectionalStream - Bidirectional stream wrapper from addon
     * @returns {Promise<void>} Resolves when audio transmission is complete
     * @private
     */
    private pipeAudioStreamToBidirectionalStream;
    /**
     * Wraps protobuf response stream to surface writer errors.
     * @param {AsyncIterable<any>} pbStream - Bidirectional stream iterable
     * @param {Promise<void>} writerPromise - Promise tracking audio writer
     * @returns {AsyncIterable<any>} Wrapped stream that propagates writer errors
     * @private
     */
    private wrapStreamWithWriter;
    /**
     * Transforms protobuf text stream to string stream.
     * @param {AsyncIterable<any>} pbStream - Protobuf message stream
     * @returns {AsyncIterable<string>} Text stream
     * @private
     */
    private transformSessionToText;
    /**
     * Converts protobuf messages to structured transcription results.
     * @param {AsyncIterable<any>} pbStream - Protobuf message stream
     * @returns {AsyncIterable<StreamingSTTTranscription>} Result stream
     * @private
     */
    private transformPbStreamToResult;
    /**
     * Extracts transcription result from a protobuf message.
     * @param {any} pbMessage - Protobuf message from the stream
     * @returns {StreamingSTTTranscription} Extracted transcription result
     * @private
     */
    private extractTranscriptionResult;
    private createStreamingSession;
}
