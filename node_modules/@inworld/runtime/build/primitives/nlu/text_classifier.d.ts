/**
 * Text Classifier primitive using N-API addon.
 */
import type { ClassifyTextRequest, TextClassifierConfig, TextClassifierResponse } from './types';
/**
 * Text Classifier class.
 * Classifies text into predefined categories (e.g., safety, sentiment, custom).
 * Requires a TextEmbedder to generate embeddings for classification.
 *
 * @example
 * ```typescript
 * import { TextEmbedder } from '../embeddings/text_embedder';
 * import { TextClassifier } from './text_classifier';
 *
 * // First, create an embedder
 * const embedder = await TextEmbedder.create({
 *   localConfig: {
 *     modelPath: 'models/embedders/bge-large-en-v1.5.gguf',
 *     device: { type: 'CPU', index: 0 }
 *   }
 * });
 *
 * // Create classifier with embedder
 * const classifier = await TextClassifier.create(embedder, {
 *   modelWeightsPath: 'models/safety/model_weights.json',
 *   supportedClasses: ['hategroup', 'selfharm', 'sexual', 'substance']
 * });
 *
 * // Classify text
 * const result = await classifier.classifyText({
 *   text: "This is a test message"
 * });
 *
 * // Check results
 * for (const cls of result.classes) {
 *   console.log(`${cls.className}: ${cls.confidence}`);
 * }
 * ```
 */
export declare class TextClassifier {
    private classifierInterface;
    /**
     * Creates a new TextClassifier instance (internal constructor).
     * Use `TextClassifier.create()` static method instead.
     *
     * @param {any} classifierInterface - Addon TextClassifierInterface instance
     * @internal
     */
    constructor(classifierInterface: any);
    /**
     * Creates a new TextClassifier instance with the specified configuration.
     * Requires a TextEmbedder to generate embeddings for text classification.
     *
     * @param {any} embedder - TextEmbedder instance for generating embeddings
     * @param {TextClassifierConfig} config - Text classifier configuration
     * @returns {Promise<TextClassifier>} Promise resolving to TextClassifier instance
     * @throws {TextClassifierError} If classifier creation fails
     *
     * @example
     * ```typescript
     * import { TextEmbedder } from '../embeddings/text_embedder';
     *
     * // Create embedder first
     * const embedder = await TextEmbedder.create({
     *   localConfig: {
     *     modelPath: 'models/embedders/my-embedder.gguf',
     *     device: { type: 'CPU', index: 0 }
     *   }
     * });
     *
     * // Create safety classifier
     * const classifier = await TextClassifier.create(embedder, {
     *   modelWeightsPath: 'models/safety/text_classifier/model_weights.json',
     *   supportedClasses: ['hategroup', 'selfharm', 'sexual', 'sexualminors', 'substance'],
     *   threshold: 0.5
     * });
     * ```
     */
    static create(embedder: any, config: TextClassifierConfig): Promise<TextClassifier>;
    /**
     * Classifies the provided text into predefined categories.
     * Returns classifications with confidence scores.
     *
     * @param {ClassifyTextRequest} request - Classification request with text and optional threshold
     * @returns {Promise<TextClassifierResponse>} Classification results
     * @throws {TextClassifierError} If classification fails
     *
     * @example
     * ```typescript
     * const result = await classifier.classifyText({
     *   text: "This is a test message",
     *   threshold: 0.6  // Optional: override default threshold
     * });
     *
     * // Check if any unsafe content detected
     * if (result.classes.length > 0) {
     *   console.log('Detected unsafe content:');
     *   result.classes.forEach(cls => {
     *     console.log(`  ${cls.className}: ${(cls.confidence * 100).toFixed(2)}%`);
     *   });
     * } else {
     *   console.log('Text is safe');
     * }
     * ```
     */
    classifyText(request: ClassifyTextRequest): Promise<TextClassifierResponse>;
    /**
     * Classifies text and returns only classes exceeding the specified threshold.
     *
     * @param {string} text - Text to classify
     * @param {number} threshold - Minimum confidence threshold (0-1)
     * @returns {Promise<TextClassifierResponse>} Filtered classification results
     * @throws {TextClassifierError} If classification fails
     *
     * @example
     * ```typescript
     * // Only get high-confidence classifications
     * const result = await classifier.classifyTextWithThreshold(
     *   "Sample text",
     *   0.8  // Only return classes with >80% confidence
     * );
     * ```
     */
    classifyTextWithThreshold(text: string, threshold: number): Promise<TextClassifierResponse>;
    /**
     * Checks if text contains any unsafe content based on classification.
     * Returns true if any class exceeds the threshold.
     *
     * @param {string} text - Text to check
     * @param {number} threshold - Optional threshold (uses config default if not provided)
     * @returns {Promise<boolean>} True if unsafe content detected
     * @throws {TextClassifierError} If classification fails
     *
     * @example
     * ```typescript
     * const text = "User message";
     * const isUnsafe = await classifier.isUnsafe(text);
     *
     * if (isUnsafe) {
     *   console.log('Content blocked: unsafe content detected');
     * } else {
     *   console.log('Content is safe to display');
     * }
     * ```
     */
    isUnsafe(text: string, threshold?: number): Promise<boolean>;
    /**
     * Checks if text contains specific unsafe categories.
     *
     * @param {string} text - Text to check
     * @param {string[]} categories - Categories to check for
     * @param {number} threshold - Optional threshold
     * @returns {Promise<boolean>} True if any specified category detected
     * @throws {TextClassifierError} If classification fails
     *
     * @example
     * ```typescript
     * // Check for specific safety categories
     * const hasHate = await classifier.containsCategories(
     *   "User message",
     *   ['hategroup', 'harassment']
     * );
     *
     * if (hasHate) {
     *   console.log('Message contains hate speech');
     * }
     * ```
     */
    containsCategories(text: string, categories: string[], threshold?: number): Promise<boolean>;
    /**
     * Gets the highest confidence classification for the text.
     * Returns null if no classifications exceed the threshold.
     *
     * @param {string} text - Text to classify
     * @param {number} threshold - Optional threshold
     * @returns {Promise<{className: string, confidence: number} | null>} Top classification or null
     * @throws {TextClassifierError} If classification fails
     *
     * @example
     * ```typescript
     * const top = await classifier.getTopClassification("Sample text");
     *
     * if (top) {
     *   console.log(`Top category: ${top.className} (${top.confidence})`);
     * } else {
     *   console.log('No significant classification');
     * }
     * ```
     */
    getTopClassification(text: string, threshold?: number): Promise<{
        className: string;
        confidence: number;
    } | null>;
    /**
     * Batch classifies multiple texts.
     *
     * @param {string[]} texts - Array of texts to classify
     * @param {number} threshold - Optional threshold
     * @returns {Promise<TextClassifierResponse[]>} Array of classification results
     * @throws {TextClassifierError} If classification fails
     *
     * @example
     * ```typescript
     * const texts = [
     *   "First message",
     *   "Second message",
     *   "Third message"
     * ];
     *
     * const results = await classifier.classifyBatch(texts);
     *
     * results.forEach((result, index) => {
     *   console.log(`Text ${index + 1}:`, result.classes);
     * });
     * ```
     */
    classifyBatch(texts: string[], threshold?: number): Promise<TextClassifierResponse[]>;
}
