/**
 * Device Registry using N-API addon.
 * Provides information about available compute devices (CPU, GPU, etc.).
 */
import type { DeviceDescriptor, DeviceType } from '../types';
/**
 * Device Registry class.
 * Queries and lists available compute devices for model execution.
 * Useful for selecting optimal devices for ML model inference.
 *
 * @example
 * ```typescript
 * // Get available devices
 * const devices = await DeviceRegistry.getAvailableDevices();
 *
 * console.log(`Found ${devices.length} devices:`);
 * devices.forEach(device => {
 *   console.log(`- ${device.type} ${device.index}: ${device.info?.name}`);
 *   console.log(`  Memory: ${device.info?.freeMemoryBytes} / ${device.info?.totalMemoryBytes} bytes`);
 * });
 *
 * // Find best GPU
 * const gpus = devices.filter(d => d.type === 'CUDA');
 * if (gpus.length > 0) {
 *   console.log('Using GPU:', gpus[0]);
 * }
 * ```
 */
export declare class DeviceRegistry {
    /**
     * Gets a list of all available compute devices.
     * Returns device descriptors with type, index, and hardware information.
     *
     * @returns {Promise<DeviceDescriptor[]>} Array of available devices
     * @throws {DeviceError} If device query fails
     *
     * @example
     * ```typescript
     * const devices = await DeviceRegistry.getAvailableDevices();
     *
     * devices.forEach(device => {
     *   console.log(`Device: ${device.type} ${device.index}`);
     *
     *   if (device.info) {
     *     console.log(`  Name: ${device.info.name}`);
     *     console.log(`  Free Memory: ${(device.info.freeMemoryBytes / 1024 / 1024).toFixed(2)} MB`);
     *     console.log(`  Total Memory: ${(device.info.totalMemoryBytes / 1024 / 1024).toFixed(2)} MB`);
     *   }
     * });
     * ```
     */
    static getAvailableDevices(): Promise<DeviceDescriptor[]>;
    /**
     * Filters devices by type.
     *
     * @param {DeviceType | string} deviceType - Device type to filter by
     * @returns {Promise<DeviceDescriptor[]>} Devices of specified type
     * @throws {DeviceError} If device query fails
     *
     * @example
     * ```typescript
     * // Get all CUDA GPUs
     * const gpus = await DeviceRegistry.getDevicesByType('CUDA');
     * console.log(`Found ${gpus.length} CUDA devices`);
     *
     * // Get CPU devices
     * const cpus = await DeviceRegistry.getDevicesByType('CPU');
     * ```
     */
    static getDevicesByType(deviceType: DeviceType | string): Promise<DeviceDescriptor[]>;
    /**
     * Gets the best available device based on available memory.
     * Prioritizes GPUs over CPUs if available.
     *
     * @returns {Promise<DeviceDescriptor | null>} Best device or null if none available
     * @throws {DeviceError} If device query fails
     *
     * @example
     * ```typescript
     * const bestDevice = await DeviceRegistry.getBestDevice();
     *
     * if (bestDevice) {
     *   console.log(`Using ${bestDevice.type} ${bestDevice.index}`);
     *
     *   // Use device for model creation
     *   const model = await Model.create({
     *     localConfig: {
     *       modelPath: 'model.onnx',
     *       device: {
     *         type: bestDevice.type,
     *         index: bestDevice.index
     *       }
     *     }
     *   });
     * } else {
     *   console.log('No devices available');
     * }
     * ```
     */
    static getBestDevice(): Promise<DeviceDescriptor | null>;
    /**
     * Gets all GPU devices (CUDA, METAL, OPENCL).
     *
     * @returns {Promise<DeviceDescriptor[]>} Array of GPU devices
     * @throws {DeviceError} If device query fails
     *
     * @example
     * ```typescript
     * const gpus = await DeviceRegistry.getGPUDevices();
     *
     * if (gpus.length > 0) {
     *   console.log('Available GPUs:');
     *   gpus.forEach((gpu, i) => {
     *     console.log(`  ${i + 1}. ${gpu.type} ${gpu.index}: ${gpu.info?.name}`);
     *   });
     * } else {
     *   console.log('No GPUs available, falling back to CPU');
     * }
     * ```
     */
    static getGPUDevices(): Promise<DeviceDescriptor[]>;
    /**
     * Gets all CPU devices.
     *
     * @returns {Promise<DeviceDescriptor[]>} Array of CPU devices
     * @throws {DeviceError} If device query fails
     *
     * @example
     * ```typescript
     * const cpus = await DeviceRegistry.getCPUDevices();
     * console.log(`${cpus.length} CPU device(s) available`);
     * ```
     */
    static getCPUDevices(): Promise<DeviceDescriptor[]>;
    /**
     * Checks if a specific device type is available.
     *
     * @param {DeviceType | string} deviceType - Device type to check
     * @returns {Promise<boolean>} True if device type is available
     * @throws {DeviceError} If device query fails
     *
     * @example
     * ```typescript
     * const hasCuda = await DeviceRegistry.hasDeviceType('CUDA');
     *
     * if (hasCuda) {
     *   console.log('CUDA GPU available, using GPU acceleration');
     * } else {
     *   console.log('No CUDA GPU, using CPU');
     * }
     * ```
     */
    static hasDeviceType(deviceType: DeviceType | string): Promise<boolean>;
    /**
     * Gets device by type and index.
     *
     * @param {DeviceType | string} deviceType - Device type
     * @param {number} index - Device index
     * @returns {Promise<DeviceDescriptor | null>} Device or null if not found
     * @throws {DeviceError} If device query fails
     *
     * @example
     * ```typescript
     * // Get second CUDA GPU
     * const gpu1 = await DeviceRegistry.getDevice('CUDA', 1);
     *
     * if (gpu1) {
     *   console.log('Using CUDA device 1');
     * } else {
     *   console.log('CUDA device 1 not available');
     * }
     * ```
     */
    static getDevice(deviceType: DeviceType | string, index: number): Promise<DeviceDescriptor | null>;
    /**
     * Gets total and free memory across all devices of a type.
     *
     * @param {DeviceType | string} deviceType - Device type
     * @returns {Promise<{total: number, free: number}>} Memory info in bytes
     * @throws {DeviceError} If device query fails
     *
     * @example
     * ```typescript
     * const cudaMemory = await DeviceRegistry.getTotalMemory('CUDA');
     *
     * console.log(`Total CUDA memory: ${(cudaMemory.total / 1024 / 1024 / 1024).toFixed(2)} GB`);
     * console.log(`Free CUDA memory: ${(cudaMemory.free / 1024 / 1024 / 1024).toFixed(2)} GB`);
     * ```
     */
    static getTotalMemory(deviceType: DeviceType | string): Promise<{
        total: number;
        free: number;
    }>;
    /**
     * Gets summary of all available devices.
     *
     * @returns {Promise<string>} Human-readable device summary
     * @throws {DeviceError} If device query fails
     *
     * @example
     * ```typescript
     * const summary = await DeviceRegistry.getSummary();
     * console.log(summary);
     * // Output:
     * // Available Devices:
     * //   CPU 0: Intel Core i9 (32 cores)
     * //   CUDA 0: NVIDIA RTX 3090 (24 GB)
     * //   CUDA 1: NVIDIA RTX 3080 (10 GB)
     * ```
     */
    static getSummary(): Promise<string>;
}
