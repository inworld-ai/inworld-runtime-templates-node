#!/usr/bin/env ts-node

import { execSync } from 'child_process';
import * as fs from 'fs';
import * as path from 'path';

/**
 * Script to generate Zod schemas from JSON Schema files
 * Uses quicktype to convert JSON Schema to TypeScript with Zod validation
 */

import {
  ADD_TYPE_SUFFIX,
  arrowFunctionBodyToString,
  ENUM_MAPPINGS,
  EXCLUDE_FROM_BUNDLE,
  GENERATE_TYPE_GUARDS,
  FIELD_MODIFIERS,
  PROPERTY_TRANSFORMERS,
  RUN_ESLINT,
  SCHEMA_REPLACEMENTS,
  TYPE_SUFFIX,
} from './postprocessing/replacements';

const GENERATED_DIR = path.join(
  __dirname,
  '..',
  '..',
  'src/internal/generated',
);
const MAIN_DIR = path.join(GENERATED_DIR, 'main');
const ZOD_DIR = path.join(__dirname, '..', '..', 'src', 'common', 'api');
const BUNDLE_SCHEMA_FILES = new Set<string>([
  'bundle.json',
  'library.json',
  'graphs.json',
]);

/**
 * Mapping of old schema reference paths to new paths after structural reorganization.
 * This handles cross-file references that need to be updated when schemas are restructured.
 * Format: { 'old.path.SchemaName': 'new.path.SchemaName' }
 */
const SCHEMA_REF_PATH_MAPPINGS: Record<string, string> = {
  // library.json schema reorganization mappings
  'ai.inworld.runtime.v1.library.DeviceSelection.jsonschema.strict.json':
    'ai.inworld.runtime.v1.library.platform.DeviceSelection.jsonschema.strict.json',
  'ai.inworld.runtime.v1.library.Language.jsonschema.strict.json':
    'ai.inworld.runtime.v1.library.core.Language.jsonschema.strict.json',
  'ai.inworld.runtime.v1.library.EntityMatch.jsonschema.strict.json':
    'ai.inworld.runtime.v1.library.nlu.EntityMatch.jsonschema.strict.json',
  'ai.inworld.runtime.v1.library.AudioFrame.jsonschema.strict.json':
    'ai.inworld.runtime.v1.library.speech.AudioChunk.jsonschema.strict.json',
};
const GENERATED_FILE_HEADER = `/**\n *\n * Note: This file is autogenerated and not intended to be modified manually.\n *\n */\n\n/* eslint-disable @typescript-eslint/no-unused-vars */\n\n`;
const REGISTERED_SCHEMA_DEFINITIONS = new Map<string, string>();
const FILE_SCHEMA_DEPENDENCIES = new Map<string, Set<string>>();
const SCHEMA_BUNDLE_CACHE = new Map<string, any>();
const SCHEMA_CANONICAL_OWNERS = new Map<string, string>();

const ENABLE_ABBREVIATION_UPPERCASE =
  (process.env.ZOD_DISABLE_ABBREVIATION_UPPERCASE ?? '').toLowerCase() !==
  'true';
const ABBREVIATIONS_TO_UPPERCASE = ['AEC', 'LLM', 'MCP', 'STT', 'TTS', 'VAD'];
const ABBREVIATION_RULES = ABBREVIATIONS_TO_UPPERCASE.map((abbr) => ({
  uppercase: abbr,
  properCase: `${abbr[0]}${abbr.slice(1).toLowerCase()}`,
}));

function normalizeAbbreviationPrefix(name: string): string {
  if (!ENABLE_ABBREVIATION_UPPERCASE || !name) {
    return name;
  }

  for (const { uppercase, properCase } of ABBREVIATION_RULES) {
    if (name.startsWith(uppercase)) {
      return name;
    }

    if (name.startsWith(properCase)) {
      return `${uppercase}${name.slice(properCase.length)}`;
    }
  }

  return name;
}

// Ensure output directory exists
if (!fs.existsSync(ZOD_DIR)) {
  fs.mkdirSync(ZOD_DIR, { recursive: true });
}

interface SchemaToGenerate {
  name: string;
  schemaFile: string | string[]; // Can be a single file or array of files
  outputFile: string;
}

interface SchemaDeduplicationResult {
  content: string;
  importsBySource: Map<string, Set<string>>;
  typeReexportsBySource: Map<string, Set<string>>;
  guardReexportsBySource: Map<string, Set<string>>;
}

interface PropertyDocInfo {
  name: string;
  title?: string;
  description?: string;
  defaultValue?: unknown;
  examples?: unknown[];
  typeLabel?: string;
  required?: boolean;
  enumValues?: unknown[];
}

interface SchemaDocInfo {
  name: string;
  title?: string;
  description?: string;
  examples?: unknown[];
  defaultValue?: unknown;
  enumValues?: unknown[];
  typeLabel?: string;
  properties: Map<string, PropertyDocInfo>;
}

function getExportedTypeName(schemaName: string): string {
  if (ADD_TYPE_SUFFIX && TYPE_SUFFIX) {
    return `${schemaName}${TYPE_SUFFIX}`;
  }
  return schemaName;
}

function loadSchemaBundle(fileName: string): any | null {
  if (SCHEMA_BUNDLE_CACHE.has(fileName)) {
    return SCHEMA_BUNDLE_CACHE.get(fileName);
  }

  const filePath = path.join(MAIN_DIR, fileName);
  if (!fs.existsSync(filePath)) {
    console.warn(
      `   ⚠ Referenced schema file "${fileName}" not found at ${filePath}`,
    );
    SCHEMA_BUNDLE_CACHE.set(fileName, null);
    return null;
  }

  const content = fs.readFileSync(filePath, 'utf-8');
  const bundle = JSON.parse(content);
  SCHEMA_BUNDLE_CACHE.set(fileName, bundle);
  return bundle;
}

/**
 * Apply schema reference path mappings to a $ref value.
 * This handles cases where schemas have been reorganized and paths have changed.
 *
 * @param {string} ref - The original $ref value
 * @returns {string} The mapped $ref value (or original if no mapping exists)
 */
function applyRefPathMapping(ref: string): string {
  // Check if this is an external file reference with a definition path
  // Format: "file.json#/$defs/schema.path.Name.jsonschema.strict.json"
  const externalRefMatch = ref.match(/^([^#]+\.json)#\/\$defs\/(.+)$/);
  if (externalRefMatch) {
    const [, fileName, defPath] = externalRefMatch;
    const mappedPath = SCHEMA_REF_PATH_MAPPINGS[defPath];
    if (mappedPath) {
      return `${fileName}#/$defs/${mappedPath}`;
    }
    return ref;
  }

  // Check if this is an internal reference
  // Format: "#/$defs/schema.path.Name.jsonschema.strict.json"
  const internalRefMatch = ref.match(/^#\/\$defs\/(.+)$/);
  if (internalRefMatch) {
    const defPath = internalRefMatch[1];
    const mappedPath = SCHEMA_REF_PATH_MAPPINGS[defPath];
    if (mappedPath) {
      return `#/$defs/${mappedPath}`;
    }
    return ref;
  }

  return ref;
}

/**
 * Recursively apply schema reference path mappings to all $ref values in a schema.
 * This function modifies the schema in place.
 *
 * @param {unknown} node - The schema node to process
 */
function applyRefPathMappingsToSchema(node: unknown): void {
  if (Array.isArray(node)) {
    for (const item of node) {
      applyRefPathMappingsToSchema(item);
    }
    return;
  }

  if (!node || typeof node !== 'object') {
    return;
  }

  for (const [key, value] of Object.entries(node)) {
    if (key === '$ref' && typeof value === 'string') {
      const mappedRef = applyRefPathMapping(value);
      if (mappedRef !== value) {
        (node as Record<string, unknown>)[key] = mappedRef;
      }
      continue;
    }

    applyRefPathMappingsToSchema(value);
  }
}

function collectExternalSchemaRefs(value: unknown): Set<string> {
  const refs = new Set<string>();

  const visit = (node: unknown) => {
    if (Array.isArray(node)) {
      for (const item of node) {
        visit(item);
      }
      return;
    }

    if (node && typeof node === 'object') {
      for (const item of Object.values(node)) {
        visit(item);
      }
      return;
    }

    if (typeof node === 'string') {
      const match = node.match(/^([^#]+\.json)#/);
      if (match) {
        refs.add(match[1]);
      }
    }
  };

  visit(value);
  return refs;
}

function mergeExternalDefinitions(
  bundle: any,
  currentFile: string,
  visited: Set<string> = new Set(),
): void {
  if (!bundle.$defs) {
    bundle.$defs = {};
  }

  visited.add(currentFile);

  // Apply reference path mappings before processing to handle schema reorganization
  applyRefPathMappingsToSchema(bundle);

  const externalFiles = Array.from(collectExternalSchemaRefs(bundle)).filter(
    (fileName) => fileName !== currentFile && !visited.has(fileName),
  );

  for (const fileName of externalFiles) {
    const externalBundle = loadSchemaBundle(fileName);
    if (!externalBundle || !externalBundle.$defs) {
      continue;
    }

    mergeExternalDefinitions(externalBundle, fileName, visited);

    for (const [defName, defSchema] of Object.entries(externalBundle.$defs)) {
      if (!bundle.$defs[defName]) {
        bundle.$defs[defName] = defSchema;
      }
    }
  }

  rewriteExternalRefs(bundle);
}

function getBaseSchemaName(defName: string): string | null {
  const match = defName.match(/\.([^.]+)\.jsonschema/i);
  if (!match) {
    return null;
  }
  return normalizeAbbreviationPrefix(match[1]);
}

function getBaseSchemaNameFromRef(ref: string): string | null {
  const match = ref.match(/\.([^.]+)\.jsonschema/i);
  if (!match) {
    return null;
  }
  return normalizeAbbreviationPrefix(match[1]);
}

function titleToSchemaName(title?: string): string | null {
  if (!title) {
    return null;
  }

  const parts = title.match(/[A-Za-z0-9]+/g);
  if (!parts || parts.length === 0) {
    return null;
  }

  const name = parts
    .map((part) => {
      if (part.length === 0) {
        return '';
      }
      return part[0].toUpperCase() + part.slice(1);
    })
    .join('');

  return normalizeAbbreviationPrefix(name);
}

function registerCanonicalOwners(): void {
  for (const schema of schemasToGenerate) {
    const schemaFiles = Array.isArray(schema.schemaFile)
      ? schema.schemaFile
      : [schema.schemaFile];

    for (const schemaFileName of schemaFiles) {
      const schemaPath = path.join(MAIN_DIR, schemaFileName);
      if (!fs.existsSync(schemaPath)) {
        continue;
      }
      const content = fs.readFileSync(schemaPath, 'utf-8');
      const json = JSON.parse(content);
      if (!json.$defs) continue;
      for (const defName of Object.keys(json.$defs)) {
        const baseName = getBaseSchemaName(defName);
        if (!baseName) continue;
        if (!SCHEMA_CANONICAL_OWNERS.has(baseName)) {
          SCHEMA_CANONICAL_OWNERS.set(baseName, schema.outputFile);
        }
      }
    }
  }
}

function resolveSchemaDependencies(schemaFiles: string[]): string[] {
  const dependencies = new Set<string>();
  const visited = new Set<string>();

  const visit = (fileName: string) => {
    if (visited.has(fileName)) {
      return;
    }
    visited.add(fileName);

    const bundle = loadSchemaBundle(fileName);
    if (!bundle) {
      return;
    }

    const refs = collectExternalSchemaRefs(bundle);
    for (const ref of refs) {
      if (!visited.has(ref)) {
        dependencies.add(ref);
        visit(ref);
      }
    }
  };

  for (const fileName of schemaFiles) {
    visit(fileName);
  }

  for (const fileName of schemaFiles) {
    dependencies.delete(fileName);
  }

  return Array.from(dependencies);
}

function rewriteExternalRefs(node: unknown): void {
  if (Array.isArray(node)) {
    for (const item of node) {
      rewriteExternalRefs(item);
    }
    return;
  }

  if (!node || typeof node !== 'object') {
    return;
  }

  for (const [key, value] of Object.entries(node)) {
    if (key === '$ref' && typeof value === 'string') {
      const match = value.match(/^([^#]+\.json)(#.*)$/);
      if (match) {
        (node as Record<string, unknown>)[key] = match[2];
      }
      continue;
    }

    rewriteExternalRefs(value);
  }
}

/**
 * Find enum schemas in the JSON schema bundle that have mappings configured
 * Returns a Map of schema name to enum mapping
 */
function findEnumsWithMappings(
  schemaPath: string,
): Map<string, Record<string, string>> {
  const schemaContent = fs.readFileSync(schemaPath, 'utf-8');
  const schema = JSON.parse(schemaContent);
  const enumsWithMappings = new Map<string, Record<string, string>>();

  // Check if there are $defs (definitions) in the schema
  if (!schema.$defs) {
    return enumsWithMappings;
  }

  // Iterate through all definitions to find enums with mappings
  for (const [defName, defSchema] of Object.entries(schema.$defs)) {
    if (typeof defSchema !== 'object' || !defSchema) continue;

    // Check properties for enums
    const properties = (defSchema as any).properties;
    if (properties && typeof properties === 'object') {
      for (const [propName, propSchema] of Object.entries(properties)) {
        if (typeof propSchema !== 'object' || !propSchema) continue;

        const propSchemaObj = propSchema as any;
        // Check if this property has enum values
        if (propSchemaObj.enum && Array.isArray(propSchemaObj.enum)) {
          const mappingKey = `${defName}#${propName}`;
          if (ENUM_MAPPINGS.has(mappingKey)) {
            enumsWithMappings.set(mappingKey, ENUM_MAPPINGS.get(mappingKey)!);
          }
        }
      }
    }
  }

  return enumsWithMappings;
}

/**
 * Fix enums that contain special numeric string values like '-Infinity', 'Infinity', 'NaN'
 * These cause TypeScript declaration errors because they're interpreted as computed property names
 * Solution: Convert these enums to use z.union with z.literal instead of z.enum
 */
function fixSpecialNumericEnums(content: string): string {
  // Pattern to match enums with special numeric values
  const specialValues = ['-Infinity', 'Infinity', 'NaN'];
  const specialValuesSet = new Set(specialValues);

  // Match: export const SomeSchema = z.enum([...]);
  const enumPattern = /export const (\w+Schema) = z\.enum\(\[([\s\S]*?)\]\);/g;

  let modifiedContent = content;
  let match;

  // Reset regex state
  enumPattern.lastIndex = 0;

  while ((match = enumPattern.exec(content)) !== null) {
    const fullMatch = match[0];
    const schemaName = match[1];
    const enumValues = match[2];

    // Check if this enum contains any special numeric values
    const hasSpecialValues = specialValues.some(
      (val) =>
        enumValues.includes(`'${val}'`) || enumValues.includes(`"${val}"`),
    );

    if (hasSpecialValues) {
      // Extract all enum values
      const valueMatches = enumValues.match(/['"]([^'"]+)['"]/g);
      if (!valueMatches) continue;

      const values = valueMatches.map((v) => v.slice(1, -1)); // Remove quotes

      // Convert to z.union with z.literal for each value
      const literals = values.map((v) => `z.literal('${v}')`).join(', ');
      const newSchema = `export const ${schemaName} = z.union([${literals}]);`;

      modifiedContent = modifiedContent.replace(fullMatch, newSchema);
      console.log(`   ✓ Fixed special numeric enum: ${schemaName}`);
    }
  }

  return modifiedContent;
}

/**
 * Apply enum mappings to generated Zod schemas
 * Replaces simple enums with union + transform for mapped enums
 */
function applyEnumMappings(
  content: string,
  enumMappings: Map<string, Record<string, string>>,
  schemaPaths: string[],
): string {
  let modifiedContent = content;

  // Read all schemas into a map for lookup
  const schemaMap = new Map<string, any>();
  for (const schemaPath of schemaPaths) {
    const schemaContent = fs.readFileSync(schemaPath, 'utf-8');
    const schema = JSON.parse(schemaContent);

    // Store schemas by their file name (from the path)
    const fileName = path.basename(schemaPath);
    schemaMap.set(fileName, schema);

    // Also index all $defs by their name for easy lookup
    if (schema.$defs) {
      for (const [defName, defSchema] of Object.entries(schema.$defs)) {
        schemaMap.set(defName, defSchema);
      }
    }
  }

  for (const [mappingKey, mapping] of enumMappings) {
    // Extract the definition name and property name from the mapping key
    // Format: "ai.inworld.runtime.v1.data.LLMChatRequest.jsonschema.strict.json#propertyName"
    const parts = mappingKey.split('#');
    if (parts.length !== 2) continue;

    const defName = parts[0];
    const propName = parts[1];

    // Try to find the schema - first by the file name, then by def name
    let defSchema = schemaMap.get(defName)?.$defs?.[defName];
    if (!defSchema) {
      defSchema = schemaMap.get(defName);
    }

    if (
      !defSchema ||
      !defSchema.properties ||
      !defSchema.properties[propName]
    ) {
      console.log(`   ⚠ Could not find property ${propName} in ${defName}`);
      continue;
    }

    const propertySchema = defSchema.properties[propName];
    const title = propertySchema.title;

    if (!title) {
      console.log(`   ⚠ Property ${propName} has no title in schema`);
      continue;
    }

    // Convert title to PascalCase for schema name
    // e.g., "Response Format" -> "ResponseFormat", "Image Detail" -> "ImageDetail"
    const schemaName = normalizeAbbreviationPrefix(
      title
        .split(' ')
        .map(
          (word: string) =>
            word.charAt(0).toUpperCase() + word.slice(1).toLowerCase(),
        )
        .join(''),
    );

    // Get the protobuf enum values
    const protobufValues = Object.values(mapping);
    const friendlyValues = Object.keys(mapping);

    // Find the enum schema definition
    const enumRegex = new RegExp(
      `export const ${schemaName}Schema = z\\.enum\\(\\[\\s*([^\\]]+)\\s*\\]\\);`,
      's',
    );

    const match = modifiedContent.match(enumRegex);
    if (!match) {
      console.log(
        `   ⚠ Could not find enum schema for ${schemaName} (from title: "${title}")`,
      );
      continue;
    }

    // Create the new schema with union and transform
    const newSchema = `export const ${schemaName}Schema = z
  .union([
    z.enum([${friendlyValues.map((v) => `'${v}'`).join(', ')}]),
  ])
  .transform((val) => {
    const mapping: Record<string, string> = {
${friendlyValues.map((fv) => `      '${fv}': '${mapping[fv]}'`).join(',\n')}
    };
    return mapping[val] || val;
  });`;

    // Replace the original enum definition
    modifiedContent = modifiedContent.replace(enumRegex, newSchema);

    console.log(`   ✓ Applied enum mapping for ${schemaName}`);
  }

  return modifiedContent;
}

/**
 * Find property transformers in the JSON schema bundle that have transformers configured
 * Returns a Map of schema name + property name to transformer code
 */
function findPropertiesWithTransformers(
  schemaPath: string,
  schemaFileName: string,
): Map<string, string> {
  const schemaContent = fs.readFileSync(schemaPath, 'utf-8');
  const schema = JSON.parse(schemaContent);
  const propertiesWithTransformers = new Map<string, string>();

  // Check if there are $defs (definitions) in the schema
  if (!schema.$defs) {
    return propertiesWithTransformers;
  }

  // Iterate through all definitions to find properties with transformers
  for (const [defName, defSchema] of Object.entries(schema.$defs)) {
    if (typeof defSchema !== 'object' || !defSchema) continue;

    // Check properties for transformers
    const properties = (defSchema as any).properties;
    if (properties && typeof properties === 'object') {
      for (const [propName, propSchema] of Object.entries(properties)) {
        const transformerKey = `${defName}#properties#${propName}`;
        const transformer = PROPERTY_TRANSFORMERS.get(transformerKey);
        if (transformer) {
          propertiesWithTransformers.set(
            transformerKey,
            arrowFunctionBodyToString(transformer, transformerKey),
          );
        }
      }
    }
  }

  return propertiesWithTransformers;
}

/**
 * Apply property transformers to generated Zod schemas
 * Replaces simple property definitions with custom transformers
 */
function applyPropertyTransformers(
  content: string,
  propertyTransformers: Map<string, string>,
): string {
  let modifiedContent = content;

  for (const [transformerKey, transformerCode] of propertyTransformers) {
    // Extract the schema name and property name from the transformer key
    // Format: "ai.inworld.runtime.v1.configs.llm.Tool.jsonschema.strict.json#properties#properties"
    const parts = transformerKey.split('#');
    if (parts.length !== 3 || parts[1] !== 'properties') {
      console.log(`   ⚠ Invalid transformer key format: ${transformerKey}`);
      continue;
    }

    // Extract schema name from the file name
    // e.g., "ai.inworld.runtime.v1.configs.llm.Tool.jsonschema.strict.json" -> "Tool"
    const schemaFileName = parts[0];
    const propertyName = parts[2];
    const schemaNameMatch = schemaFileName.match(/\.([^.]+)\.jsonschema/);
    if (!schemaNameMatch) {
      console.log(
        `   ⚠ Could not extract schema name from: ${schemaFileName}`,
      );
      continue;
    }

    const schemaName = normalizeAbbreviationPrefix(schemaNameMatch[1]);

    // Find the schema object definition that contains this property
    // Pattern: export const ToolSchema = z.object({ ... properties: z.string(), ... });
    // We need to match the property and its trailing comma if present
    // Property names might be quoted or unquoted, e.g., "properties": or properties:
    const schemaObjectRegex = new RegExp(
      `(export const ${schemaName}Schema = z\\.object\\(\\{[\\s\\S]*?[\\s\\n]+)(["']?${propertyName}["']?:\\s*[^,\\n]+)(,?)([\\s\\S]*?\\}\\);)`,
      's',
    );

    let match = modifiedContent.match(schemaObjectRegex);
    if (!match) {
      // Try a simpler pattern if the first one doesn't match
      const simpleRegex = new RegExp(
        `(export const ${schemaName}Schema = z\\.object\\(\\{[^}]*?)(["']?${propertyName}["']?:\\s*[^,\\n}]+)(,?)([^}]*?\\}\\);)`,
        's',
      );
      match = modifiedContent.match(simpleRegex);
    }

    if (!match) {
      console.log(
        `   ⚠ Could not find property ${propertyName} in ${schemaName}Schema`,
      );
      continue;
    }

    // Replace the property definition with the transformer code
    const beforeProperty = match[1];
    const oldPropertyDef = match[2];
    const trailingComma = match[3];
    const afterProperty = match[4];

    // Check if the property name was quoted in the original
    const wasQuoted = oldPropertyDef.match(/^["']/);
    const quoteChar = wasQuoted ? oldPropertyDef[0] : '';

    // The transformer code should already include the property name prefix
    const newPropertyDef = quoteChar
      ? `${quoteChar}${propertyName}${quoteChar}: ${transformerCode}`
      : `${propertyName}: ${transformerCode}`;

    const newSchema = `${beforeProperty}${newPropertyDef}${trailingComma}${afterProperty}`;

    // Replace the original schema definition
    modifiedContent = modifiedContent.replace(schemaObjectRegex, newSchema);

    console.log(
      `   ✓ Applied property transformer for ${schemaName}.${propertyName}`,
    );
  }

  return modifiedContent;
}

/**
 * Find field modifiers in the JSON schema bundle that have modifiers configured
 * Returns a Map of schema name + field name to modifier code
 */
function findFieldsWithModifiers(
  schemaPath: string,
  schemaFileName: string,
): Map<string, string> {
  const schemaContent = fs.readFileSync(schemaPath, 'utf-8');
  const schema = JSON.parse(schemaContent);
  const fieldsWithModifiers = new Map<string, string>();

  // Check if there are $defs (definitions) in the schema
  if (!schema.$defs) {
    return fieldsWithModifiers;
  }

  // Iterate through all definitions to find fields with modifiers
  for (const [defName, defSchema] of Object.entries(schema.$defs)) {
    if (typeof defSchema !== 'object' || !defSchema) continue;

    // Check properties for modifiers
    const properties = (defSchema as any).properties;
    if (properties && typeof properties === 'object') {
      for (const [propName] of Object.entries(properties)) {
        // The defName in the bundle is already the full schema file name
        // e.g., "ai.inworld.runtime.v1.data.LLMChatRequest.jsonschema.strict.json"
        const modifierKey = `${defName}#${propName}`;
        const modifier = FIELD_MODIFIERS.get(modifierKey);
        if (modifier) {
          fieldsWithModifiers.set(
            modifierKey,
            arrowFunctionBodyToString(modifier, modifierKey),
          );
        }
      }
    }
  }

  return fieldsWithModifiers;
}

/**
 * Apply exact schema replacements to generated Zod schemas
 * Performs simple text replacements for exact matches
 *
 * @param {string} content - The generated schema file content
 * @returns {string} Modified content with replacements applied
 */
function applySchemaReplacements(content: string): string {
  let modifiedContent = content;
  let replacementCount = 0;

  for (const [searchString, replaceString] of SCHEMA_REPLACEMENTS) {
    const occurrences = (
      modifiedContent.match(new RegExp(escapeRegExp(searchString), 'g')) || []
    ).length;

    if (occurrences > 0) {
      modifiedContent = modifiedContent.replace(
        new RegExp(escapeRegExp(searchString), 'g'),
        replaceString,
      );
      replacementCount += occurrences;
      console.log(
        `   ✓ Replaced "${searchString}" with "${replaceString}" (${occurrences} occurrence(s))`,
      );
    }
  }

  if (replacementCount === 0) {
    console.log(`   No schema replacements found`);
  }

  return modifiedContent;
}

/**
 * Escapes special regex characters in a string
 *
 * @param {string} string - String to escape
 * @returns {string} Escaped string safe for use in RegExp
 */
function escapeRegExp(string: string): string {
  return string.replace(/[.*+?^${}()|[\]\\]/g, '\\$&');
}

/**
 * Apply field modifiers to generated Zod schemas
 * Replaces field values with custom Zod schemas (e.g., adding .default(), .optional(), etc.)
 */
function applyFieldModifiers(
  content: string,
  fieldModifiers: Map<string, string>,
): string {
  let modifiedContent = content;

  for (const [modifierKey, modifierCode] of fieldModifiers) {
    // Extract the field name from the modifier key
    // Format: "ai.inworld.runtime.v1.data.LLMChatRequest.jsonschema.strict.json#responseFormat"
    const parts = modifierKey.split('#');
    if (parts.length !== 2) {
      console.log(`   ⚠ Invalid modifier key format: ${modifierKey}`);
      continue;
    }

    const keySchemaFileName = parts[0];
    const fieldName = parts[1];

    // Extract schema name from the file name
    // e.g., "ai.inworld.runtime.v1.data.LLMChatRequest.jsonschema.strict.json" -> "LLMChatRequest"
    const schemaNameMatch = keySchemaFileName.match(/\.([^.]+)\.jsonschema/);
    if (!schemaNameMatch) {
      console.log(
        `   ⚠ Could not extract schema name from: ${keySchemaFileName}`,
      );
      continue;
    }

    const schemaName = schemaNameMatch[1];

    // Convert schema name from bundle format to quicktype format
    // quicktype converts consecutive capitals to PascalCase (e.g., LLMChatRequest -> LlmChatRequest)
    // We need to handle this naming conversion
    const normalizedSchemaName = schemaName
      .toLowerCase()
      .replace(/[^a-z0-9]/gi, '');

    // Use a simpler approach: find the schema definition first, then look for the field within it
    const schemaDefPattern = new RegExp(
      `export const (\\w+)Schema = z\\.object\\(\\{[\\s\\S]*?\\}\\);`,
      'g',
    );

    let foundSchemaName: string | null = null;
    let schemaBlock: string | null = null;

    const schemaMatches = [...modifiedContent.matchAll(schemaDefPattern)];

    for (const schemaMatch of schemaMatches) {
      const candidateSchemaName = schemaMatch[1];
      const normalizedCandidate = candidateSchemaName
        ? candidateSchemaName.toLowerCase()
        : '';

      if (normalizedCandidate === normalizedSchemaName) {
        // Check if this schema block contains the field
        const blockContent = schemaMatch[0];
        const fieldPattern = new RegExp(
          `["']?${fieldName}["']?:\\s*[^,\\n}]+`,
          '',
        );
        if (fieldPattern.test(blockContent)) {
          foundSchemaName = candidateSchemaName;
          schemaBlock = blockContent;
          break;
        }
      }
    }

    if (!foundSchemaName || !schemaBlock) {
      console.log(
        `   ⚠ Could not find field ${fieldName} in ${schemaName}Schema`,
      );
      continue;
    }

    // Now replace just the field line within the schema block
    // Pattern: fieldName: FieldSchema, or fieldName: FieldSchema.something(),
    // We need to match the complete value including nested structures like z.union([...])
    // So we'll match everything until we find a comma followed by whitespace and a quote/word (next field)
    // or until we find a closing brace (end of object)
    const fieldLinePattern = new RegExp(
      `(\\s+)(["']?${fieldName}["']?:\\s*)((?:[^,}]|,(?!\\s*["'}]))+)(,?)`,
      '',
    );

    const fieldMatch = schemaBlock.match(fieldLinePattern);
    if (!fieldMatch) {
      console.log(
        `   ⚠ Could not match field line for ${fieldName} in ${foundSchemaName}Schema`,
      );
      continue;
    }

    const whitespace = fieldMatch[1];
    const fieldPrefix = fieldMatch[2];
    const trailingComma = fieldMatch[4];

    // Replace the field value entirely with the modifier code
    const newFieldLine = `${whitespace}${fieldPrefix}${modifierCode}${trailingComma}`;

    // Replace the field line in the content
    // Important: We need to replace the field line within the specific schema block,
    // not in the entire content, to avoid replacing similar field names in other schemas
    const originalFieldLine = fieldMatch[0];
    const newSchemaBlock = schemaBlock.replace(originalFieldLine, newFieldLine);
    modifiedContent = modifiedContent.replace(schemaBlock, newSchemaBlock);

    console.log(
      `   ✓ Applied field modifier for ${foundSchemaName}.${fieldName}`,
    );
  }

  return modifiedContent;
}

/**
 * Scan the main directory for all JSON schema bundle files
 * @returns {string[]} Array of schema file names (excluding those in EXCLUDE_FROM_BUNDLE)
 */
function scanSchemaFiles(): string[] {
  const files = fs.readdirSync(MAIN_DIR);
  return files.filter(
    (file) =>
      file.endsWith('.jsonschema.strict.bundle.json') &&
      !EXCLUDE_FROM_BUNDLE.includes(file),
  );
}

/**
 * Transform bundle.json to individual schema files that quicktype can process
 * Quicktype needs actual top-level schemas, not just $defs.
 * This function extracts each $def and creates separate temp schema files.
 *
 * @param {string} bundlePath - Path to bundle.json
 * @returns {string[]} Array of paths to the temporary schema files
 */
function createQuicktypeCompatibleBundle(bundlePath: string): string[] {
  const bundleContent = fs.readFileSync(bundlePath, 'utf-8');
  const bundle = JSON.parse(bundleContent);
  const bundleFileName = path.basename(bundlePath);
  const originalDefNames = Object.keys(bundle.$defs || {});

  if (!bundle.$defs) {
    throw new Error('bundle.json does not contain $defs');
  }

  mergeExternalDefinitions(bundle, bundleFileName);

  const tempDir = path.join(MAIN_DIR, '.bundle-temp');

  // Create temp directory
  if (fs.existsSync(tempDir)) {
    // Clean up any existing temp files
    fs.rmSync(tempDir, { recursive: true, force: true });
  }
  fs.mkdirSync(tempDir, { recursive: true });

  // Write the modified bundle (with reference mappings applied) to a temp file
  // so that quicktype can follow references to the corrected paths
  const tempBundlePath = path.join(tempDir, bundleFileName);
  fs.writeFileSync(tempBundlePath, JSON.stringify(bundle, null, 2), 'utf-8');

  const tempFiles: string[] = [];

  // Extract each original $def (before merging external ones) as standalone schema file
  for (const defName of originalDefNames) {
    const defSchema = bundle.$defs[defName];
    if (!defSchema) {
      continue;
    }

    const baseName = getBaseSchemaName(defName) ?? defName;

    // Create a lightweight schema that references the definition inside the temp bundle.
    // Quicktype will follow the $ref back into the temp bundle file (which has
    // all required $defs merged and reference paths fixed via mergeExternalDefinitions).
    const standaloneSchema = {
      $schema: 'https://json-schema.org/draft/2020-12/schema',
      $id: defName,
      title: baseName,
      $ref: `${bundleFileName}#/$defs/${defName}`,
    };

    // Write to a temporary file
    const tempFilePath = path.join(tempDir, `${defName}`);
    fs.writeFileSync(
      tempFilePath,
      JSON.stringify(standaloneSchema, null, 2),
      'utf-8',
    );
    tempFiles.push(tempFilePath);
  }

  console.log(`   ✓ Created ${tempFiles.length} temporary schema files`);

  return tempFiles;
}

function extractSchemaNames(content: string): string[] {
  const schemaNames: string[] = [];
  const schemaDefRegex = /export const (\w+)Schema = /g;
  let match: RegExpExecArray | null;
  while ((match = schemaDefRegex.exec(content)) !== null) {
    schemaNames.push(match[1]);
  }

  return schemaNames;
}

function normalizeSchemaNamePrefixes(content: string): {
  content: string;
  normalizedCount: number;
} {
  if (!ENABLE_ABBREVIATION_UPPERCASE) {
    return { content, normalizedCount: 0 };
  }

  const schemaNames = extractSchemaNames(content);
  const renameMap = new Map<string, string>();

  for (const schemaName of schemaNames) {
    const normalized = normalizeAbbreviationPrefix(schemaName);
    if (normalized !== schemaName) {
      renameMap.set(schemaName, normalized);
    }
  }

  if (renameMap.size === 0) {
    return { content, normalizedCount: 0 };
  }

  let normalizedContent = content;
  const sortedEntries = Array.from(renameMap.entries()).sort(
    (a, b) => b[0].length - a[0].length,
  );

  for (const [from, to] of sortedEntries) {
    const pattern = new RegExp(from, 'g');
    normalizedContent = normalizedContent.replace(pattern, to);
  }

  return { content: normalizedContent, normalizedCount: renameMap.size };
}

function removeSchemaDefinition(content: string, schemaName: string): string {
  const pattern = `export const ${schemaName}Schema =`;
  const startIndex = content.indexOf(pattern);
  if (startIndex === -1) {
    return content;
  }

  let index = startIndex + pattern.length;
  let depthParen = 0;
  let depthBrace = 0;
  let depthBracket = 0;
  let inSingleQuote = false;
  let inDoubleQuote = false;
  let inTemplateLiteral = false;
  let inLineComment = false;
  let inBlockComment = false;

  const advance = (step = 1) => {
    index += step;
  };

  while (index < content.length) {
    const char = content[index];
    const nextChar = content[index + 1];

    if (inLineComment) {
      if (char === '\n') {
        inLineComment = false;
      }
      advance();
      continue;
    }

    if (inBlockComment) {
      if (char === '*' && nextChar === '/') {
        inBlockComment = false;
        advance(2);
        continue;
      }
      advance();
      continue;
    }

    if (inSingleQuote || inDoubleQuote || inTemplateLiteral) {
      if (char === '\\') {
        advance(2);
        continue;
      }

      if (inTemplateLiteral && char === '$' && nextChar === '{') {
        depthBrace++;
        advance(2);
        continue;
      }

      if (
        (inSingleQuote && char === "'") ||
        (inDoubleQuote && char === '"') ||
        (inTemplateLiteral && char === '`')
      ) {
        if (inTemplateLiteral && depthBrace > 0) {
          advance();
          continue;
        }
        inSingleQuote = false;
        inDoubleQuote = false;
        inTemplateLiteral = false;
      }
      advance();
      continue;
    }

    if (char === '/' && nextChar === '/') {
      inLineComment = true;
      advance(2);
      continue;
    }

    if (char === '/' && nextChar === '*') {
      inBlockComment = true;
      advance(2);
      continue;
    }

    if (char === "'") {
      inSingleQuote = true;
      advance();
      continue;
    }

    if (char === '"') {
      inDoubleQuote = true;
      advance();
      continue;
    }

    if (char === '`') {
      inTemplateLiteral = true;
      advance();
      continue;
    }

    switch (char) {
      case '(':
        depthParen++;
        break;
      case ')':
        if (depthParen > 0) depthParen--;
        break;
      case '{':
        depthBrace++;
        break;
      case '}':
        if (depthBrace > 0) depthBrace--;
        break;
      case '[':
        depthBracket++;
        break;
      case ']':
        if (depthBracket > 0) depthBracket--;
        break;
      case ';':
        if (depthParen === 0 && depthBrace === 0 && depthBracket === 0) {
          advance();
          while (index < content.length && /\s/.test(content[index])) {
            advance();
          }
          return `${content.slice(0, startIndex)}${content.slice(index)}`;
        }
        break;
      default:
        break;
    }

    advance();
  }

  return content;
}

function removeTypeDefinition(
  content: string,
  schemaName: string,
): { content: string; removed: boolean } {
  const typeName = getExportedTypeName(schemaName);
  const pattern = `export type ${typeName}`;
  const startIndex = content.indexOf(pattern);
  if (startIndex === -1) {
    return { content, removed: false };
  }

  let endIndex = startIndex;
  while (endIndex < content.length && content[endIndex] !== ';') {
    endIndex++;
  }
  if (endIndex >= content.length) {
    return { content, removed: false };
  }
  endIndex++;

  while (
    endIndex < content.length &&
    (content[endIndex] === '\r' || content[endIndex] === '\n')
  ) {
    endIndex++;
  }

  const removalStart = findDocCommentStart(content, startIndex);
  const updated = content.slice(0, removalStart) + content.slice(endIndex);
  return { content: updated, removed: true };
}

function removeTypeGuardFunction(
  content: string,
  schemaName: string,
): { content: string; removed: boolean } {
  const functionName = `is${schemaName}`;
  const pattern = `export function ${functionName}`;
  const startIndex = content.indexOf(pattern);
  if (startIndex === -1) {
    return { content, removed: false };
  }

  const bodyStart = content.indexOf('{', startIndex);
  if (bodyStart === -1) {
    return { content, removed: false };
  }

  let index = bodyStart + 1;
  let depth = 1;

  while (index < content.length && depth > 0) {
    const char = content[index];
    if (char === '{') {
      depth++;
    } else if (char === '}') {
      depth--;
    }
    index++;
  }

  const removalStart = findDocCommentStart(content, startIndex);
  while (
    index < content.length &&
    (content[index] === '\r' || content[index] === '\n')
  ) {
    index++;
  }

  const updated = content.slice(0, removalStart) + content.slice(index);
  return { content: updated, removed: true };
}

function findDocCommentStart(content: string, index: number): number {
  let cursor = index;
  while (cursor > 0 && /\s/.test(content[cursor - 1])) {
    cursor--;
  }

  if (cursor >= 2 && content.slice(cursor - 2, cursor) === '*/') {
    const commentEnd = cursor - 2;
    const commentStart = content.lastIndexOf('/**', commentEnd);
    if (commentStart !== -1) {
      const between = content.slice(commentEnd + 2, index).trim();
      if (between === '') {
        return commentStart;
      }
    }
  }

  return index;
}

function deduplicateSchemas(
  content: string,
  currentFile: string,
): SchemaDeduplicationResult {
  const importsBySource = new Map<string, Set<string>>();
  const typeReexportsBySource = new Map<string, Set<string>>();
  const guardReexportsBySource = new Map<string, Set<string>>();
  const schemaNames = extractSchemaNames(content);

  for (const schemaName of schemaNames) {
    const canonicalOwner = SCHEMA_CANONICAL_OWNERS.get(schemaName);
    const registeredOwner = REGISTERED_SCHEMA_DEFINITIONS.get(schemaName);

    if (canonicalOwner && canonicalOwner !== currentFile) {
      if (registeredOwner) {
        content = removeSchemaDefinition(content, schemaName);
        if (!importsBySource.has(registeredOwner)) {
          importsBySource.set(registeredOwner, new Set());
        }
        importsBySource.get(registeredOwner)!.add(`${schemaName}Schema`);
        continue;
      }
      // Canonical owner exists but has not produced this schema yet.
      // Keep the definition in the current file for now.
    }

    if (registeredOwner) {
      const sourceFile = registeredOwner;
      content = removeSchemaDefinition(content, schemaName);
      const typeRemoval = removeTypeDefinition(content, schemaName);
      content = typeRemoval.content;
      const guardRemoval = removeTypeGuardFunction(content, schemaName);
      content = guardRemoval.content;

      if (!importsBySource.has(sourceFile)) {
        importsBySource.set(sourceFile, new Set());
      }
      importsBySource.get(sourceFile)!.add(`${schemaName}Schema`);

      if (typeRemoval.removed) {
        if (!typeReexportsBySource.has(sourceFile)) {
          typeReexportsBySource.set(sourceFile, new Set());
        }
        typeReexportsBySource
          .get(sourceFile)!
          .add(getExportedTypeName(schemaName));
      }

      if (guardRemoval.removed) {
        if (!guardReexportsBySource.has(sourceFile)) {
          guardReexportsBySource.set(sourceFile, new Set());
        }
        guardReexportsBySource.get(sourceFile)!.add(`is${schemaName}`);
      }

      continue;
    }

    REGISTERED_SCHEMA_DEFINITIONS.set(schemaName, currentFile);
    if (!FILE_SCHEMA_DEPENDENCIES.has(currentFile)) {
      FILE_SCHEMA_DEPENDENCIES.set(currentFile, new Set());
    }
    FILE_SCHEMA_DEPENDENCIES.get(currentFile)!.add(`${schemaName}Schema`);
  }

  return {
    content,
    importsBySource,
    typeReexportsBySource,
    guardReexportsBySource,
  };
}

function getRelativeImportPath(fromFile: string, toFile: string): string {
  const fromPath = path.join(ZOD_DIR, fromFile);
  const toPath = path.join(ZOD_DIR, toFile);
  let relativePath = path.relative(path.dirname(fromPath), toPath);
  relativePath = relativePath.replace(/\\/g, '/');
  if (!relativePath.startsWith('.')) {
    relativePath = `./${relativePath}`;
  }
  return relativePath.replace(/\.ts$/, '');
}

function buildImportBlock(
  importsBySource: Map<string, Set<string>>,
  currentFile: string,
): string {
  if (importsBySource.size === 0) {
    return '';
  }

  const statements: string[] = [];
  for (const [sourceFile, schemaNames] of importsBySource) {
    const importPath = getRelativeImportPath(currentFile, sourceFile);
    const sortedNames = Array.from(schemaNames).sort();
    statements.push(
      `import { ${sortedNames.join(', ')} } from '${importPath}';`,
    );
  }

  return `${statements.join('\n')}\n\n`;
}

function buildReexportBlock(
  reexportsBySource: Map<string, Set<string>>,
  currentFile: string,
  options: { typeOnly?: boolean } = {},
): string {
  if (reexportsBySource.size === 0) {
    return '';
  }

  const statements: string[] = [];
  for (const [sourceFile, exportNames] of reexportsBySource) {
    const importPath = getRelativeImportPath(currentFile, sourceFile);
    const sortedNames = Array.from(exportNames).sort();
    if (options.typeOnly) {
      statements.push(
        `export type { ${sortedNames.join(', ')} } from '${importPath}';`,
      );
    } else {
      statements.push(
        `export { ${sortedNames.join(', ')} } from '${importPath}';`,
      );
    }
  }

  return `${statements.join('\n')}\n\n`;
}

function formatDefaultValue(value: unknown): string {
  if (typeof value === 'string') {
    return `"${value}"`;
  }
  if (typeof value === 'number' || typeof value === 'boolean') {
    return `${value}`;
  }
  if (value === null) {
    return 'null';
  }
  try {
    return JSON.stringify(value);
  } catch {
    return String(value);
  }
}

function toParagraphs(value?: string): string[] {
  if (!value) {
    return [];
  }
  return value
    .split(/\r?\n\s*\r?\n/)
    .map((block) =>
      block
        .split(/\r?\n/)
        .map((line) => line.trim())
        .filter(Boolean)
        .join(' '),
    )
    .filter(Boolean);
}

function toSingleLine(value?: string): string | undefined {
  if (!value) {
    return undefined;
  }
  return value
    .split(/\r?\n/)
    .map((line) => line.trim())
    .filter(Boolean)
    .join(' ');
}

function determineJsDocType(
  schema: any,
  depth = 0,
  fallback?: string,
): string | undefined {
  if (!schema || typeof schema !== 'object' || depth > 3) {
    return fallback;
  }

  if (Array.isArray(schema.enum) && schema.enum.length > 0) {
    return schema.enum
      .map((value: unknown) => {
        if (typeof value === 'string') {
          return `'${value}'`;
        }
        return formatDefaultValue(value);
      })
      .join(' | ');
  }

  if (typeof schema.type === 'string') {
    switch (schema.type) {
      case 'string':
        return 'string';
      case 'number':
      case 'integer':
        return 'number';
      case 'boolean':
        return 'boolean';
      case 'null':
        return 'null';
      case 'array': {
        const itemType = determineJsDocType(schema.items, depth + 1, 'unknown');
        return `${itemType ?? 'unknown'}[]`;
      }
      case 'object':
        return 'Record<string, unknown>';
      default:
        break;
    }
  }

  if (Array.isArray(schema.type) && schema.type.length > 0) {
    const parts = schema.type
      .map((t: string) => determineJsDocType({ type: t }, depth + 1))
      .filter(Boolean);
    if (parts.length > 0) {
      return parts.join(' | ');
    }
  }

  const ref = schema.$ref;
  if (typeof ref === 'string') {
    const refName = getBaseSchemaNameFromRef(ref);
    if (refName) {
      return getExportedTypeName(refName);
    }
  }

  for (const key of ['anyOf', 'oneOf', 'allOf'] as const) {
    const collection = schema[key];
    if (Array.isArray(collection) && collection.length > 0) {
      const parts = collection
        .map((item: any) => determineJsDocType(item, depth + 1))
        .filter(Boolean);
      if (parts.length > 0) {
        return parts.join(' | ');
      }
    }
  }

  if (schema.items) {
    const itemType = determineJsDocType(schema.items, depth + 1);
    if (itemType) {
      return `${itemType}[]`;
    }
  }

  return fallback;
}

function replaceEnumConstantsInText(
  text: string | undefined,
  protoToFriendly: Map<string, string>,
): string | undefined {
  if (!text) {
    return text;
  }

  let updated = text;
  for (const [protoValue, friendlyValue] of protoToFriendly) {
    const pattern = new RegExp(`\\b${escapeRegExp(protoValue)}\\b`, 'g');
    updated = updated.replace(pattern, friendlyValue);
  }
  return updated;
}

function collectSchemaDocs(schemaPath: string): Map<string, SchemaDocInfo> {
  const docs = new Map<string, SchemaDocInfo>();
  const schemaContent = fs.readFileSync(schemaPath, 'utf-8');
  const schema = JSON.parse(schemaContent);

  if (!schema.$defs) {
    return docs;
  }

  for (const [defName, defSchema] of Object.entries(schema.$defs)) {
    if (typeof defSchema !== 'object' || !defSchema) {
      continue;
    }

    const baseName = getBaseSchemaName(defName);
    if (!baseName) {
      continue;
    }

    const properties = new Map<string, PropertyDocInfo>();
    const requiredFields = new Set<string>(
      Array.isArray((defSchema as any).required)
        ? ((defSchema as any).required as string[])
        : [],
    );

    if ((defSchema as any).properties) {
      for (const [propName, propSchema] of Object.entries(
        (defSchema as any).properties,
      )) {
        if (typeof propSchema !== 'object' || !propSchema) {
          continue;
        }

        properties.set(propName, {
          name: propName,
          title: (propSchema as any).title,
          description: (propSchema as any).description,
          defaultValue: (propSchema as any).default,
          examples: Array.isArray((propSchema as any).examples)
            ? ((propSchema as any).examples as unknown[])
            : undefined,
          typeLabel: determineJsDocType(propSchema),
          required: requiredFields.has(propName),
          enumValues: Array.isArray((propSchema as any).enum)
            ? ((propSchema as any).enum as unknown[])
            : undefined,
        });
      }
    }

    const docInfo: SchemaDocInfo = {
      name: baseName,
      title: (defSchema as any).title,
      description: (defSchema as any).description,
      examples: Array.isArray((defSchema as any).examples)
        ? ((defSchema as any).examples as unknown[])
        : undefined,
      defaultValue: (defSchema as any).default,
      enumValues: Array.isArray((defSchema as any).enum)
        ? ((defSchema as any).enum as unknown[])
        : undefined,
      typeLabel: determineJsDocType(defSchema),
      properties,
    };

    docs.set(baseName, docInfo);

    const derivedTitle = titleToSchemaName((defSchema as any).title);
    if (derivedTitle && derivedTitle !== baseName && !docs.has(derivedTitle)) {
      docs.set(derivedTitle, {
        ...docInfo,
        name: derivedTitle,
      });
    }

    for (const propDoc of properties.values()) {
      const propSchema = (defSchema as any).properties?.[propDoc.name];
      if (!propSchema || typeof propSchema !== 'object') {
        continue;
      }

      const propTitle = (propSchema as any).title;
      if (!propTitle) {
        continue;
      }

      const derivedName = titleToSchemaName(propTitle);
      if (!derivedName) {
        continue;
      }

      if (docs.has(derivedName)) {
        const existing = docs.get(derivedName)!;
        if (
          !existing.description &&
          ((propSchema as any).description ?? propDoc.description)
        ) {
          existing.description =
            (propSchema as any).description ?? propDoc.description ?? undefined;
        }
        if (!existing.examples && propDoc.examples) {
          existing.examples = propDoc.examples;
        }
        if (
          existing.defaultValue === undefined &&
          propDoc.defaultValue !== undefined
        ) {
          existing.defaultValue = propDoc.defaultValue;
        }
        if (!existing.enumValues && propDoc.enumValues) {
          existing.enumValues = propDoc.enumValues;
        }
        if (!existing.typeLabel && propDoc.typeLabel) {
          existing.typeLabel = propDoc.typeLabel;
        }
        continue;
      }

      docs.set(derivedName, {
        name: derivedName,
        title: propTitle,
        description:
          (propSchema as any).description ?? propDoc.description ?? undefined,
        examples: Array.isArray((propSchema as any).examples)
          ? ((propSchema as any).examples as unknown[])
          : propDoc.examples,
        defaultValue:
          (propSchema as any).default ?? propDoc.defaultValue ?? undefined,
        enumValues: Array.isArray((propSchema as any).enum)
          ? ((propSchema as any).enum as unknown[])
          : propDoc.enumValues,
        typeLabel: determineJsDocType(propSchema, 0, propDoc.typeLabel),
        properties: new Map(),
      });
    }
  }

  return docs;
}

function mergeSchemaDocs(
  target: Map<string, SchemaDocInfo>,
  source: Map<string, SchemaDocInfo>,
): void {
  for (const [schemaName, doc] of source) {
    if (!target.has(schemaName)) {
      target.set(schemaName, doc);
      continue;
    }

    const existing = target.get(schemaName)!;
    if (!existing.description && doc.description) {
      existing.description = doc.description;
    }
    if (!existing.title && doc.title) {
      existing.title = doc.title;
    }
    if (!existing.examples && doc.examples) {
      existing.examples = doc.examples;
    }
    if (existing.defaultValue === undefined && doc.defaultValue !== undefined) {
      existing.defaultValue = doc.defaultValue;
    }
    if (!existing.enumValues && doc.enumValues) {
      existing.enumValues = doc.enumValues;
    }
    if (!existing.typeLabel && doc.typeLabel) {
      existing.typeLabel = doc.typeLabel;
    }

    for (const [propName, propDoc] of doc.properties) {
      if (!existing.properties.has(propName)) {
        existing.properties.set(propName, propDoc);
      }
    }
  }
}

function formatJsDocBlock(lines: string[], indent = ''): string {
  if (lines.length === 0) {
    return '';
  }

  const normalizedLines = lines.map((line) => line.replace(/\s+$/u, ''));
  const docLines = [`${indent}/**`];
  for (const line of normalizedLines) {
    if (line === '') {
      docLines.push(`${indent} *`);
    } else {
      docLines.push(`${indent} * ${line}`);
    }
  }
  docLines.push(`${indent} */\n`);
  return docLines.join('\n');
}

function buildSchemaCommentLines(doc: SchemaDocInfo): string[] {
  const lines: string[] = [];
  const paragraphs = [
    ...toParagraphs(doc.title),
    ...toParagraphs(
      doc.description && doc.description !== doc.title
        ? doc.description
        : undefined,
    ),
  ];

  for (const paragraph of paragraphs) {
    lines.push(paragraph);
    lines.push('');
  }

  if (lines.length > 0 && lines[lines.length - 1] === '') {
    lines.pop();
  }

  if (doc.examples && doc.examples.length > 0) {
    if (lines.length > 0) {
      lines.push('');
    }
    for (const example of doc.examples) {
      lines.push(`@example ${formatDefaultValue(example)}`);
    }
  }

  if (doc.enumValues && doc.enumValues.length > 0) {
    if (lines.length > 0) {
      lines.push('');
    }
    lines.push(
      `Allowed values: ${doc.enumValues
        .map((value) => formatDefaultValue(value))
        .join(', ')}`,
    );
  }

  if (doc.typeLabel && doc.properties.size === 0) {
    if (lines.length > 0) {
      lines.push('');
    }
    lines.push(`Type: ${doc.typeLabel}.`);
  }

  if (doc.defaultValue !== undefined) {
    if (lines.length > 0) {
      lines.push('');
    }
    lines.push(`Default: ${formatDefaultValue(doc.defaultValue)}.`);
  }

  return lines;
}

function buildPropertyLines(doc: SchemaDocInfo): string[] {
  if (doc.properties.size === 0) {
    return [];
  }

  const lines: string[] = [];
  const sortedProps = Array.from(doc.properties.values()).sort((a, b) =>
    a.name.localeCompare(b.name),
  );

  for (const prop of sortedProps) {
    const propertyName = prop.required ? prop.name : `[${prop.name}]`;
    const typeLabel = prop.typeLabel ?? 'unknown';
    const descriptionParts = [
      toSingleLine(prop.title),
      prop.description && prop.description !== prop.title
        ? toSingleLine(prop.description)
        : undefined,
    ]
      .filter(Boolean)
      .join('. ')
      .trim();

    let propertyLine = `@property {${typeLabel}} ${propertyName}`;
    if (descriptionParts) {
      propertyLine += ` - ${descriptionParts}`;
    }
    if (prop.defaultValue !== undefined) {
      propertyLine += ` Default: ${formatDefaultValue(prop.defaultValue)}.`;
    }
    lines.push(propertyLine.trim());

    if (prop.examples && prop.examples.length > 0) {
      for (const example of prop.examples) {
        lines.push(
          `@example ${prop.name} ${formatDefaultValue(example)}`.trim(),
        );
      }
    }

    if (prop.enumValues && prop.enumValues.length > 0) {
      lines.push(
        `@remarks ${prop.name} allowed values: ${prop.enumValues
          .map((value) => formatDefaultValue(value))
          .join(', ')}`,
      );
    }
  }

  return lines;
}

function applyFriendlyEnumDocs(
  schemaDocs: Map<string, SchemaDocInfo>,
  enumMappings: Map<string, Record<string, string>>,
): void {
  for (const [mappingKey, mapping] of enumMappings) {
    const [defName, propName] = mappingKey.split('#');
    if (!defName || !propName) {
      continue;
    }

    const friendlyValues = Object.keys(mapping);
    if (friendlyValues.length === 0) {
      continue;
    }

    const unionTypeLabel = friendlyValues
      .map((value) => `'${value}'`)
      .join(' | ');

    const protoToFriendly = new Map<string, string>();
    for (const [friendlyValue, protoValue] of Object.entries(mapping)) {
      protoToFriendly.set(protoValue, friendlyValue);
    }

    const baseName = getBaseSchemaName(defName);
    if (!baseName) {
      continue;
    }

    const parentDoc = schemaDocs.get(baseName);
    const propertyDoc = parentDoc?.properties.get(propName);
    if (propertyDoc) {
      propertyDoc.enumValues = friendlyValues;
      if (unionTypeLabel) {
        propertyDoc.typeLabel = unionTypeLabel;
      }
      propertyDoc.description = replaceEnumConstantsInText(
        propertyDoc.description,
        protoToFriendly,
      );
      propertyDoc.title = replaceEnumConstantsInText(
        propertyDoc.title,
        protoToFriendly,
      );

      if (propertyDoc.title) {
        const derivedName = titleToSchemaName(propertyDoc.title);
        if (derivedName) {
          const inlineDoc = schemaDocs.get(derivedName);
          if (inlineDoc) {
            inlineDoc.enumValues = friendlyValues;
            if (unionTypeLabel) {
              inlineDoc.typeLabel = unionTypeLabel;
            }
            inlineDoc.description = replaceEnumConstantsInText(
              inlineDoc.description,
              protoToFriendly,
            );
            inlineDoc.title = replaceEnumConstantsInText(
              inlineDoc.title,
              protoToFriendly,
            );
          }
        }
      }
    }
  }
}

function stripLeadingLineComments(
  content: string,
  startIndex: number,
): { content: string; newIndex: number } {
  let currentIndex = startIndex;

  while (currentIndex > 0) {
    const previousNewline = content.lastIndexOf('\n', currentIndex - 2);
    const lineStart = previousNewline === -1 ? 0 : previousNewline + 1;
    const line = content.slice(lineStart, currentIndex);
    const trimmed = line.trim();
    if (trimmed.startsWith('//') || trimmed === '') {
      content = `${content.slice(0, lineStart)}${content.slice(currentIndex)}`;
      currentIndex = lineStart;
      continue;
    }
    break;
  }

  return { content, newIndex: currentIndex };
}

function insertCommentBefore(
  content: string,
  searchValue: string,
  lines: string[],
): string {
  if (lines.length === 0) {
    return content;
  }

  const initialIndex = content.indexOf(searchValue);
  if (initialIndex === -1) {
    return content;
  }

  const lineStart = content.lastIndexOf('\n', initialIndex);
  let insertionIndex = lineStart === -1 ? 0 : lineStart + 1;
  const stripResult = stripLeadingLineComments(content, insertionIndex);
  content = stripResult.content;
  insertionIndex = stripResult.newIndex;

  const updatedIndex = content.indexOf(searchValue);
  if (updatedIndex === -1) {
    return content;
  }

  const indentMatch = content.slice(insertionIndex, updatedIndex).match(/^\s*/);
  const indent = indentMatch ? indentMatch[0] : '';
  const commentBlock = formatJsDocBlock(lines, indent);
  return `${content.slice(0, insertionIndex)}${commentBlock}${content.slice(
    insertionIndex,
  )}`;
}

function injectJsDoc(
  content: string,
  schemaDocs: Map<string, SchemaDocInfo>,
): string {
  let modifiedContent = content;

  for (const [schemaName, doc] of schemaDocs) {
    const schemaDeclaration = `export const ${schemaName}Schema =`;
    const hasSchemaDeclaration = modifiedContent.includes(schemaDeclaration);
    const typeRegex = new RegExp(
      `export type (\\w+) = z\\.infer<typeof ${schemaName}Schema>;`,
    );
    const typeMatch = modifiedContent.match(typeRegex);

    if (!hasSchemaDeclaration && !typeMatch) {
      continue;
    }

    const schemaCommentLines = buildSchemaCommentLines(doc);
    if (hasSchemaDeclaration) {
      modifiedContent = insertCommentBefore(
        modifiedContent,
        schemaDeclaration,
        schemaCommentLines,
      );
    }

    if (typeMatch) {
      const propertyLines = buildPropertyLines(doc);
      const typeCommentLines = [
        ...schemaCommentLines,
        ...(propertyLines.length > 0 ? [''] : []),
        ...propertyLines,
      ].filter((line, index, arr) => !(line === '' && arr[index - 1] === ''));

      modifiedContent = insertCommentBefore(
        modifiedContent,
        typeMatch[0],
        typeCommentLines,
      );
    }
  }

  return modifiedContent;
}

function insertAfterHeader(content: string, block: string): string {
  if (content.startsWith(GENERATED_FILE_HEADER)) {
    return `${GENERATED_FILE_HEADER}${block}${content.slice(
      GENERATED_FILE_HEADER.length,
    )}`;
  }

  return `${block}${content}`;
}

const schemasToGenerate: SchemaToGenerate[] = [
  {
    name: 'Library',
    schemaFile: 'library.json',
    outputFile: 'library.ts',
  },
  {
    name: 'Graphs',
    schemaFile: 'graphs.json',
    outputFile: 'graphs.ts',
  },
];

registerCanonicalOwners();

console.log('🚀 Starting Zod schema generation...\n');

for (const schema of schemasToGenerate) {
  const outputPath = path.join(ZOD_DIR, schema.outputFile);
  const schemaFiles = Array.isArray(schema.schemaFile)
    ? schema.schemaFile
    : [schema.schemaFile];
  const schemaPaths = schemaFiles.map((file) => path.join(MAIN_DIR, file));
  const dependencySchemaFiles = resolveSchemaDependencies(schemaFiles);
  const metadataSchemaFiles = Array.from(
    new Set([...schemaFiles, ...dependencySchemaFiles]),
  );
  const metadataSchemaPaths = metadataSchemaFiles.map((file) =>
    path.join(MAIN_DIR, file),
  );

  console.log(`📝 Generating Zod schema for ${schema.name}...`);
  if (schemaFiles.length === 1) {
    console.log(`   Input:  ${path.basename(schemaPaths[0])}`);
  } else {
    console.log(`   Input:  ${schemaFiles.length} schema files`);
    console.log(`   First:  ${path.basename(schemaFiles[0])}`);
    console.log(
      `   Last:   ${path.basename(schemaFiles[schemaFiles.length - 1])}`,
    );
  }
  console.log(`   Output: ${outputPath}`);

  // Check that all schema files exist
  for (const schemaPath of schemaPaths) {
    if (!fs.existsSync(schemaPath)) {
      console.error(`❌ Schema file not found: ${schemaPath}`);
      process.exit(1);
    }
  }

  // Track if we need to clean up temp files
  let tempFiles: string[] = [];
  let tempDir: string | null = null;

  try {
    // If using bundle.json, transform it to a quicktype-compatible format
    let actualSchemaPaths = schemaPaths;
    if (schemaFiles.length === 1 && BUNDLE_SCHEMA_FILES.has(schemaFiles[0])) {
      console.log(
        `   Transforming ${schemaFiles[0]} for quicktype compatibility...`,
      );
      tempFiles = createQuicktypeCompatibleBundle(schemaPaths[0]);
      actualSchemaPaths = tempFiles;
      tempDir = path.join(MAIN_DIR, '.bundle-temp');
    }

    // Use quicktype to convert JSON Schema to TypeScript with Zod
    // Multiple schema files can be passed to quicktype separated by spaces
    const schemaPathsQuoted = actualSchemaPaths.map((p) => `"${p}"`).join(' ');
    const command = `quicktype ${schemaPathsQuoted} -o "${outputPath}" --lang typescript-zod --src-lang schema --no-ignore-json-refs`;

    execSync(command, {
      stdio: 'inherit',
      cwd: path.join(__dirname, '..', '..'),
    });

    // Post-process the generated file
    let content = fs.readFileSync(outputPath, 'utf-8');

    const normalizationResult = normalizeSchemaNamePrefixes(content);
    content = normalizationResult.content;
    if (normalizationResult.normalizedCount > 0) {
      console.log(
        `   ✓ Normalized ${normalizationResult.normalizedCount} schema name(s) with uppercase abbreviations`,
      );
    }

    // Fix special numeric enums (like '-Infinity', 'Infinity', 'NaN')
    console.log(`   Checking for special numeric enums...`);
    content = fixSpecialNumericEnums(content);

    // For bundle with multiple schemas, collect all mappings/transformers/modifiers from all files
    const allEnumMappings = new Map<string, Record<string, string>>();
    const allPropertyTransformers = new Map<string, string>();
    const allFieldModifiers = new Map<string, string>();
    const schemaDocs = new Map<string, SchemaDocInfo>();

    // Use original schema paths for finding mappings/transformers (not the temp file)
    for (let i = 0; i < metadataSchemaPaths.length; i++) {
      const schemaPath = metadataSchemaPaths[i];
      const schemaFileName = metadataSchemaFiles[i];

      // Collect enum mappings
      const enumMappings = findEnumsWithMappings(schemaPath);
      for (const [key, value] of enumMappings) {
        allEnumMappings.set(key, value);
      }

      // Collect property transformers
      const propertyTransformers = findPropertiesWithTransformers(
        schemaPath,
        schemaFileName,
      );
      for (const [key, value] of propertyTransformers) {
        allPropertyTransformers.set(key, value);
      }

      // Collect field modifiers
      const fieldModifiers = findFieldsWithModifiers(
        schemaPath,
        schemaFileName,
      );
      for (const [key, value] of fieldModifiers) {
        allFieldModifiers.set(key, value);
      }

      const collectedDocs = collectSchemaDocs(schemaPath);
      mergeSchemaDocs(schemaDocs, collectedDocs);
    }

    if (allEnumMappings.size > 0) {
      applyFriendlyEnumDocs(schemaDocs, allEnumMappings);
    }

    // Apply enum mappings if configured
    if (allEnumMappings.size > 0) {
      console.log(
        `   Found ${allEnumMappings.size} enum(s) with mappings, applying transformations...`,
      );
      // Pass all schema paths so we can look up properties across all schemas
      content = applyEnumMappings(
        content,
        allEnumMappings,
        metadataSchemaPaths,
      );
    }

    // Apply property transformers if configured
    if (allPropertyTransformers.size > 0) {
      console.log(
        `   Found ${allPropertyTransformers.size} property/properties with transformers, applying transformations...`,
      );
      content = applyPropertyTransformers(content, allPropertyTransformers);
    }

    // Apply field modifiers if configured
    if (allFieldModifiers.size > 0) {
      console.log(
        `   Found ${allFieldModifiers.size} field(s) with modifiers, applying modifications...`,
      );
      content = applyFieldModifiers(content, allFieldModifiers);
    }

    // Apply exact schema replacements if configured
    if (SCHEMA_REPLACEMENTS.size > 0) {
      console.log(
        `   Applying ${SCHEMA_REPLACEMENTS.size} exact schema replacement(s)...`,
      );
      content = applySchemaReplacements(content);
    }

    if (ADD_TYPE_SUFFIX && TYPE_SUFFIX) {
      console.log(`   Adding "${TYPE_SUFFIX}" suffix to type names...`);

      // Find all type definitions: export type TypeName = z.infer<typeof TypeNameSchema>;
      // We need to:
      // 1. Change type name: export type TypeName -> export type TypeNameInterface
      // 2. Keep schema name unchanged: TypeNameSchema stays as is

      // Match pattern: export type [TypeName] = z.infer<typeof [TypeName]Schema>;
      const typeDefPattern =
        /export type (\w+) = z\.infer<typeof (\w+)Schema>;/g;

      // First, collect all type names that need to be renamed
      const typeMapping: Map<string, string> = new Map();
      let match;
      while ((match = typeDefPattern.exec(content)) !== null) {
        const typeName = match[1];
        const newTypeName = typeName + TYPE_SUFFIX;
        typeMapping.set(typeName, newTypeName);
      }

      // Now replace type definitions
      content = content.replace(
        /export type (\w+) = z\.infer<typeof (\w+)Schema>;/g,
        (match, typeName, schemaBaseName) => {
          return `export type ${typeName}${TYPE_SUFFIX} = z.infer<typeof ${schemaBaseName}Schema>;`;
        },
      );

      console.log(
        `   ✓ Added "${TYPE_SUFFIX}" suffix to ${typeMapping.size} types`,
      );
    }

    // Generate type guard functions for each type
    if (GENERATE_TYPE_GUARDS) {
      console.log(`   Generating type guard functions...`);

      // Find all schema definitions: export const TypeNameSchema = ...
      const schemaDefPattern = /export const (\w+)Schema = /g;

      const typeGuards: string[] = [];
      let match;
      while ((match = schemaDefPattern.exec(content)) !== null) {
        const schemaBaseName = match[1]; // e.g., "Text" from "TextSchema"
        const typeName = getExportedTypeName(schemaBaseName); // includes suffix if enabled
        const functionName = `is${schemaBaseName}`; // e.g., "isText"

        const typeGuard = `export function ${functionName}(obj: unknown): obj is ${typeName} {
  return ${schemaBaseName}Schema.safeParse(obj).success;
}`;

        typeGuards.push(typeGuard);
      }

      // Append all type guards at the end of the file
      if (typeGuards.length > 0) {
        content = content + '\n\n' + typeGuards.join('\n\n');
        console.log(`   ✓ Generated ${typeGuards.length} type guard functions`);
      }
    }

    const deduplicationResult = deduplicateSchemas(content, schema.outputFile);
    content = deduplicationResult.content;
    const importBlock = buildImportBlock(
      deduplicationResult.importsBySource,
      schema.outputFile,
    );
    const typeReexportBlock = buildReexportBlock(
      deduplicationResult.typeReexportsBySource,
      schema.outputFile,
      { typeOnly: true },
    );
    const guardReexportBlock = buildReexportBlock(
      deduplicationResult.guardReexportsBySource,
      schema.outputFile,
    );

    // Add autogenerated file header if missing
    if (!content.startsWith(GENERATED_FILE_HEADER)) {
      content = `${GENERATED_FILE_HEADER}${content}`;
    }

    const headerBlocks = [importBlock, typeReexportBlock, guardReexportBlock]
      .filter(Boolean)
      .join('');

    // Insert imports/re-exports after header if dedup introduced dependencies
    if (headerBlocks) {
      content = insertAfterHeader(content, headerBlocks);
    }

    if (schemaDocs.size > 0) {
      console.log(`   Injecting JsDoc comments...`);
      content = injectJsDoc(content, schemaDocs);
    }

    const registeredSchemasForFile = FILE_SCHEMA_DEPENDENCIES.get(
      schema.outputFile,
    );
    if (registeredSchemasForFile && registeredSchemasForFile.size > 0) {
      const schemaList = Array.from(registeredSchemasForFile).sort();
      const preview = schemaList.slice(0, 5);
      const suffix =
        schemaList.length > 5 ? `, ... (+${schemaList.length - 5} more)` : '';
      console.log(
        `   Dependencies registered for ${schema.outputFile}: ${preview.join(', ')}${suffix}`,
      );
    }

    if (deduplicationResult.importsBySource.size > 0) {
      for (const [
        sourceFile,
        schemaNames,
      ] of deduplicationResult.importsBySource) {
        const sortedNames = Array.from(schemaNames).sort();
        console.log(
          `   Reused schemas from ${sourceFile}: ${sortedNames.join(', ')}`,
        );
      }
    }

    // Write the modified content back to file
    fs.writeFileSync(outputPath, content, 'utf-8');

    // Run eslint --fix to format the generated file
    if (RUN_ESLINT) {
      console.log(`   Running eslint --fix...`);
      try {
        execSync(`eslint "${outputPath}" --fix`, {
          cwd: path.join(__dirname, '..', '..'),
          stdio: 'pipe', // Suppress eslint output
        });
        console.log(`   ✓ Code formatted with eslint`);
      } catch (error) {
        // eslint might exit with non-zero if there are unfixable issues
        // but that's okay, we still want to continue
        console.log(`   ⚠ eslint completed with warnings (this is normal)`);
      }
    }

    console.log(`✅ Successfully generated ${schema.outputFile}\n`);
  } catch (error) {
    console.error(`❌ Error generating ${schema.name}:`, error);
    process.exit(1);
  } finally {
    // Clean up temporary directory if created
    if (tempDir && fs.existsSync(tempDir)) {
      fs.rmSync(tempDir, { recursive: true, force: true });
      console.log(`   🧹 Cleaned up ${tempFiles.length} temporary files`);
    }
  }
}

if (FILE_SCHEMA_DEPENDENCIES.size > 0) {
  const dependencyManifest: Record<string, string[]> = {};
  for (const [fileName, schemaSet] of FILE_SCHEMA_DEPENDENCIES) {
    dependencyManifest[fileName] = Array.from(schemaSet).sort();
  }
  const manifestPath = path.join(ZOD_DIR, 'schema-dependencies.json');
  fs.writeFileSync(
    manifestPath,
    JSON.stringify(dependencyManifest, null, 2),
    'utf-8',
  );
  console.log(`🗂  Schema dependency manifest saved to ${manifestPath}`);
}

console.log('🎉 Zod schema generation complete!');
console.log(`📂 Schemas generated in: ${ZOD_DIR}`);
